\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


This is just a really quick blog post capturing an idea which I
thought was profound, excited to develop this more in a
philosophy paper that I'm going to write soon.

Context: 
I've been thinking about ethics a bit lately. 
I think it's good to know arguments for and against any
positions that I take. (This is of course debatable, maybe there
are some things that you are better off not knowing the
arguments one way for. But I think this is generally not the
case.)

So within ethics, one of the major philosophies is
**utilitarianism**: you *should* try to maximize total "goodness"
as measured by some utility function.

A related stance is 
"If something bad is going to happen, and you can prevent it
without causing any other substantial moral bad stuff to happen,
then you should do it."

Classic ex:
- You see a little boy (named Bob) drowning in the Charles River while you
    are walking to class. Your backpack with your laptop in it
    are currently glued to your back. You are morally obligated
    to save little Bob, even though it will mean damaging
    your possesions, because those are not morally significant
    compared to Bob's life. 

This reasoning seems to extend to the following conclusion:

- If you ever buy something superflous, then you are evil you
    could have donated that money to preventing starvation or
    death from malaria or bad diseases.


To make the dillema personal the effective altruist would
essentially tell me: 
- You are morally obligated to get a job doing quant and make
    big moneys and donate all of them to charity. And of course
    not indulge in any luxuries. Most of all not waste time in silly
    selfish things like math puzzles. 

I haven't fully formulated a response to this argument yet, or
even decided whether / to what extent I agree or disagree with
it. (Although my inaction is also certainly a choice, just not a
very intentional one, which is likely worse than intentionally
making a decision.)

Anyways, this blog post is for the following idea:

> "What should I do? Live a **good** life."

But what exactly is a **good** life?

Being moral / developing virtue is an important part of a good
life.
But it is not, in my opinion, the only part.
There are other important factors to "the good life".

This doesn't exempt me from donating to charity. 
But it does give a potential reason why it might be rational to
not feel guilty about not devoting my life to making money and
donating it to charity. Because although that kind of sounds a
little bit epic, it actually just sounds not super meaningful.

So what I'm saying is this:
Assume for a moment that it really is *morally wrong* to not
donate all your money to charity.

If your definition of *should* is "you should do $X$ if $X$ is
important in your pursuit of the good life" then arguably 
"not doing $Y$ is morally wrong" needn't entail 
"you should do $Y$".
That is, maybe its ok to do things that are morally wrong (like
refusing to donate all your moneys to charity).
If it is more important to your good life that you immerse
yourself in meaningful projects, relationships, etc than to do
the morally right thing then maybe that is reason sufficient for
you to be correct in asserting "I should do $X$, even though $X$
precludes fully doing $Y$."

It still sounds a little bit crazy.
Maybe this is all just wishful thinking, out of a desire to not
to do the morally right things.
It certainly does sound strange to say "you needn't (in the
normative 'should' sense) do things which are morally required of you".

But I think there's something here. 
Maybe.
If you have any good thoughts about why I am  totally and utterly
wrong, or about what qualms you have about the altruistic
argument I would be very interested to hear them! 



