<blockquote>
<p>What classes are you taking?<br />
- literally everyone. Not that it’s a bad question, in-fact it’s probably a rather good question. But it just feels a tad over-used atm.</p>
</blockquote>
<ul>
<li>stochastic processes</li>
<li>analysis of boolean functions</li>
<li>geometric algorithms</li>
<li>seminar in number theory</li>
<li>writing short stories (afaict? although there was some mess-up with the registration so I’m not sure).</li>
<li>NOT: advanced complexity. [Note to self: drop this once the HASS situation is clarified.]</li>
</ul>
<h2 id="stochastic-processes">stochastic processes</h2>
<p>This is probably the class I’m most excited for.</p>
<p>First class we talked about the threshold at which <span class="math inline">\(G(n,p_n)\)</span> is connected. Turns out it is precisely <span class="math inline">\(p_n = \frac{\ln n}{n}\)</span>.</p>
<p>proof sketch:</p>
<div class="prop envbox">
<p><strong>Proposition.</strong> Fix constant <span class="math inline">\(\lambda &lt; 1\)</span> If <span class="math inline">\(p_n = \lambda \frac{\ln n}{n}\)</span> then whp the graph is disconnected.</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> For each <span class="math inline">\(v\in V\)</span> let <span class="math inline">\(I_v\)</span> denote the event that <span class="math inline">\(v\)</span> is <strong>isolated</strong> (no edges incident to <span class="math inline">\(v\)</span> survive). Let <span class="math inline">\(X\)</span> be the number of isolated vertices. For any fixed <span class="math inline">\(v\)</span> we have <span class="math display">\[\Pr[I_v] = (1- p_n)^{n-1} \approx \exp(-(n-1)p_n) \approx 1/n^{\lambda}.\]</span> For example this could be <span class="math inline">\(1/n^{.999}\)</span>.</p>
<p>Hence, <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}[X] \approx n^{1-\lambda}\)</span>, which you can think of as <span class="math inline">\(n^{.001} \to \infty\)</span>. So, in expectation we have a very large number of isolated vertices, which is great.</p>
<p>Analyze the variance, it’s well-concentrated. Hence, whp at least one isolated vertex. Isolated vertex means in particular that graph is disconnected.</p>
</div>
<div class="prop envbox">
<p><strong>Proposition.</strong> Fix constant <span class="math inline">\(\lambda &gt; 1\)</span>. If <span class="math inline">\(p_n = \lambda \frac{\ln n}{n}\)</span> then whp the graph is connected.</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> For any <span class="math inline">\(S\subseteq V\)</span> with <span class="math inline">\(|S|\le |V|/2\)</span>, define the <span class="math inline">\(E_S\)</span> as the event that there are no edges between <span class="math inline">\(S, V\setminus S\)</span>. Then <span class="math display">\[\Pr[\text{graph disconnected}] \le \sum_{S} \Pr[E_S] \le
\sum_{k=1}^{\left\lfloor n/2 \right\rfloor} \binom{n}{k} \Pr[[k]\times([n]\setminus
[k]) \cap E = \varnothing] \le \sum_{k=1}^{\left\lfloor n/2 \right\rfloor}(1-p)^{k(n-k)} \binom{n}{k}.\]</span></p>
<p>And it turns out that this goes to <span class="math inline">\(0\)</span> as <span class="math inline">\(n\to \infty\)</span>.</p>
</div>
<p>Today we talked about branching processes. You have an infinite <span class="math inline">\(d\)</span>-ary tree and you delete each edge with probability <span class="math inline">\(p\)</span>. This is apparently a special case of “percolation”.</p>
<p>One question of interest is, “What is the chance that there is an infinite component?”</p>
<p>Turns out the answer is that there is a threshold at <span class="math inline">\(p=1/d\)</span>.</p>
<p><strong>TODO: think a bit more about why looking at root component is all you need to do: does that pr threshold as well?</strong></p>
<p>One really interesting thing about this was that we used / proved the Payley-Zygmund inequality, which is really trippy in some sense, because it almost seems like the opposite of chebyshev. It’s proof is just “Cauchy Shwarz” but I still want to understand intuition more.</p>
<p><strong>TODO: get more intuition for this inequality</strong></p>
<h2 id="boolean-functions">boolean functions</h2>
<p>We did definitions and motivations. But it just seems very elegant.</p>
<p>Let me prove some basic things really as a way of writing down stuff to remember it:</p>
<div class="prop envbox">
<p><strong>Proposition.</strong> <span class="math display">\[\mathop{\mathrm{\mathbb{E}}}f = f(\varnothing), \mathop{\mathrm{\text{Var}}}f = \sum_{S\neq \varnothing} \hat{f}(S)^2.\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong></p>
<p>Recall the characters are defined as, for each <span class="math inline">\(S\subseteq [n]\)</span>, <span class="math display">\[\chi_S: \{\pm 1\}^{n} \to \pm 1, x\mapsto \prod_{i\in S} x_i.\]</span></p>
<p>Recall we define the inner product as <span class="math display">\[\langle f,g \rangle = \mathop{\mathrm{\mathbb{E}}}_x f(x) g(x).\]</span> Thus <span class="math display">\[\mathop{\mathrm{\mathbb{E}}}f = \langle f, 1 \rangle = \langle f, \chi_\varnothing \rangle = f(\varnothing).\]</span></p>
<p>Let <span class="math inline">\(g=f-\mathop{\mathrm{\mathbb{E}}}f.\)</span> We claim that <span class="math inline">\(\hat{g}(S)\)</span> is the same as <span class="math inline">\(\hat{f}(S)\)</span> on all non-empty <span class="math inline">\(S\)</span>, but that <span class="math inline">\(\hat{g}(\varnothing) = 0\)</span>.</p>
<p>Recall, <span class="math display">\[\hat{g}(S) = \langle g, \chi_S \rangle = \mathop{\mathrm{\mathbb{E}}}_x g(x)\chi_S(x) = \mathop{\mathrm{\mathbb{E}}}_x f(x)
\chi_S(x) - \mathop{\mathrm{\mathbb{E}}}_x\chi_S(x) \mathop{\mathrm{\mathbb{E}}}f.\]</span> Now the important fact is that <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}\chi_S = 0\)</span> unless <span class="math inline">\(S=\varnothing\)</span>, in which case <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}\chi_\varnothing = 1.\)</span> Hence, <span class="math display">\[\hat{g}(S) = \hat{f}(S) - 1_{S=\varnothing} \cdot f(\varnothing).\]</span> Thus our claim about the fourier spectrum of <span class="math inline">\(g\)</span> is correct.</p>
<p>Finally, we compute <span class="math inline">\(\mathop{\mathrm{\text{Var}}}f = ||g||^2\)</span> using Parseval’s Equality, which says</p>
<p><span class="math display">\[||g||^2 = \sum_{S\subseteq [n]} \hat{g}(S)^2.\]</span> Which concludes the proof.</p>
</div>
<h2 id="geometric-algos">geometric algos</h2>
<p>closest pair:</p>
<ul>
<li>sort y coord</li>
<li>split in half horizontally</li>
<li>then there is a vertical column left</li>
<li>sweep line on the vertical column</li>
<li>sweep line is OP because by packing argument it’s O(1) checks per point</li>
</ul>
<p>even faster:</p>
<ul>
<li>“gridding”: hash stuff to boxes.</li>
</ul>
<p>As a historical note, closest pair is probably the first algorithm I ever cared about, in particular due to needing to solve this for a video game “theland”</p>
<h2 id="nt">NT</h2>
<p>This class is seeming likely to be my most challenging class. In the combinatorics / algorithms classes I feel very comfortable. The ideas are neat and novel, but I understand the language.</p>
<p>NT is a foreign language so far. Partly I think this is a result of the textbook. The textbook assumes that the reader is really comfortable with basic results of algebra / topology / analysis; however, I’m a bit rusty.</p>
<p>This all said, I think it’ll be a great time. This is very likely the final non-(algorithms, combinatorics) math class I’ll ever take. I don’t think algebra / analysis will ever end up being super relevant to stuff I do. But I think it’ll be fun to pick up a little foreign language, and just learn some really different stuff than what I’m used to.</p>
<p>I hope this can also be an opportunity to learn some other skills along the lines of “doing hard things”. I’m not saying that “doing hard things” is intrinsically meaningful in general. But it often can be. And I’ve been curious about NT for a while. I think algebra / analysis is kinda fancy and neat.</p>
<p>So, why am I taking this class? Because I think numbers are kinda cool and want to know some ridiculously heavy machinery for looking at numbers.</p>
<p>That said, note to self, <em>do not take commutative algebra, analysis or number theory in the future… stick to algos+combo :p</em>.</p>
<h2 id="writing-stories">writing stories</h2>
<p>should be fun time, hope I can take it.</p>
<h2 id="misc-thoughts">misc thoughts</h2>
<p>Anyways, all in all, I’m taking some interesting classes and it can be a good time.</p>
<p>But it’s also important to remember to do other stuff, like making good food, walking around boston, and doing research.</p>
<p>add oil!</p>
