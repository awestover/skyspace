{title}
cool classes
{contents}

{description}
I'm too busy to write a proper post atm. But have been seeing
some really neat things in classes, breifly jotting a note to
self about them.
{body}

# modular forms

So why do we care about the modular group
$G=SL_2(\Z)/\set{-1,1}$?

Well actually the answer has to do with complex lattices.
The most important thing to know about complex lattices is the
following fact:

beg thm
$$ \set{1,z}, \set{az+b, cz+d} $$ 
generate the **same** lattice, when $ad-bc=1$.
end thm
beg pf
The first lattice is obviously contained in the second. The fact
that the matrix abcd is invertible in $SL_2(\Z)$ shows the other inclusion.
end pf

So what does this mean?
Well, suppose that we consider $\setof{(u,w)}{u,w\in \C}$ modulo we
consider  $(u,w)\equiv (u',w')$ if $u/w = u'/w'$.
This is called **homothety**.
Of course this is in correspondence with $\C$.
But then there is an interesting and natural way to define an
action of $SL_2(\Z)$ on this equivalence class of vectors: matrix
multiplication.

So FACT:
beg thm
Let $H$ be the upper half plane, $G$ the modular group, $R$ the
set of complex lattices and $R/\C$ mean lattices modulo
homothety.
Then,
$H/G \cong R/\C. $
end thm

Ok, so lattices are actually something rather interesting and
motivated so now it maybe makes a bit more sense why we care
about the modular group.

Here's an example of a modular form:
$$ G_k(\Gamma) = \sum_{\gamma\in \Gamma}\frac{1}{|\gamma|^{2k}}.  $$ 

Yeah so that's a very nice object and it's related to the modular
group because we showed that the modular group is in some sense
related to lattices.

# boolean anlaysis

A trick for sampling things in a $p$-biased measure when you want
them to have disjoint supports.
You put them in buckets and then sample with $1/2$ measure.

# coupling

Talked about coupling in probability class.

So, what is this why do we care.
Well, there's this notion of TV distance between distributions:

$$ d_{TV}(P,Q) = \frac{1}{2}\sum_x |P(x)-Q(x)| = \sup_{\text{events }A} P(A)-Q(Q) = \inf_{\text{couplings }X,Y} \Pr[P(X)\neq P(Y)].$$ 

So we are interested in analyzing mixing times of markov chains:
how many steps do you have to go before the TV distance is small?

And a nice way to do this is by giving a coupling and arguing
"locally" that the coupling causes $P(X)\neq P(Y)$ to decrease.

