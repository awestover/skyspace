{title}
more concentration inequalities
{contents}

{description}
FKG, Janson
{body}

brevity is ~~the soul of wit~~ fast ig

# FKG

FKG says if $F,G$ are **increasing** functions of independent
random variables $X_1,\ldots,
X_n$ then we have

$$ \E[FG] \ge \E[F]\E[G]. $$ 

For instance, suppose that $X_1,\ldots, X_n$ are whether edges
exist in erdos renyi graph.
And $F$ was the indicator of "existence of a 4-clique" and $G$
was the indicator of "graph is connected".
Then the inequality reads

"Probability of being connected and containing a 4-clique is
larger than if you pretended like these were independent events."

Or if $F$ was "number of triangles in graph" then you have
"expected number of triangles conditional on having a 4-clique is
larger than expected number of triangles with no conditioning."

This makes a lot of sense: positively correlated things should
help each other out.

# janson 

[yufei's notes](https://ocw.mit.edu/courses/18-226-probabilistic-method-in-combinatorics-fall-2020/mit18_226f20_lec15-16.pdf)

Let $R$ be a random subset of $[n]$ generated somehow.
Let $A_i$ be the event that $S_i\subseteq R$. 
Let $X = \sum_i \one_{A_i}$.
Define
$$ \Delta = \sum_{A\neq B, A\not\perp B} \E[I_A I_B] $$ 

Then you get a tail bound
$$ \Pr[X\le \E X - t]\le \exp(\frac{-t^2}{2(\mu+\Delta)}). $$ 

prototypical example: analyze number of triangles in graph.

