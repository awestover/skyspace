\renewcommand{\O}{\mathcal{O}}
\newcommand{\tilo}{\widetilde{\O}}
\newcommand{\nil}{\varnothing}
\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}
\newcommand{\legendre}[2]{\genfrac{(}{)}{}{}{#1}{#2}}
\newcommand{\EXP}{\mathsf{EXP}}
\newcommand{\PSPACE}{\mathsf{PSPACE}}
\newcommand{\NEXP}{\mathsf{NEXP}}
\newcommand{\PP}{\mathsf{P}}
\newcommand{\NP}{\mathsf{NP}}
\newcommand{\erdos}{Erd\H{o}s}
\newcommand{\pmo}{\set{-1,1}}
\newcommand{\zo}{\set{0,1}}


\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


Very often you have some norms and you want to compare them.

<div class="defn envbox">**Definition.**
Let $f:\set{-1,1}\to \R$. Define the p-norm as 
$$ ||f||_p = \left(\E_x |f(x)|^{p}\right)^{1/p}. $$ 
</div>
<div class="ex envbox">**Example.**
$$ ||f||_1 = \E_x |f(x)|, $$ 
$$ ||f||_\infty = \sup_x |f(x)|. $$ 
</div>

It is easy to see that for all $p<q$ we have
$$ ||f||_p \le ||f||_q. $$ 

But what if you wanted the inequality to point the other way?
It turns out that for nice enough functions you can get something
kind of like this.

Intuition:
If $f = \sum_i a_i x_i$, i.e., a centered degree-1 function, 
then  $f(x)$ for random $x$ in the hypercube should by tightly
concentrated around zero. 

<div class="thm envbox">**Theorem.**
If $f$ is degree at most $d$ then we have

$$ ||f||_q \le \sqrt{q-1}^{d} ||f||_2.  $$ 
</div>
<div class="pf envbox">**Proof.**
Induction and Cauchy-Shwarz
</div>

<div class="rmk envbox">**Remark.**
There is another interpretation of this in terms of the noisy
hypercube.

Noisy hypercube is a Markov Chain. Starting from a vertex for
each coordinate independently you either stay or resample the
value uniformly randomly.

You can think of this as a weighted graph too. 

Or as a linear operator that does smoothing.

You can prove that the smoothed version of $f$ with this noisy
thing has 
$$ ||T_\rho f||_q \le ||f||_p $$ 
for $1\le p\le q\le \infty$
and  $0\le \rho \le \sqrt{\frac{p-1}{q-1}}$.

</div>

<div class="rmk envbox">**Remark.**
There is an interpretation of this in terms of small-set-expanders.

I think it says that if you think about $T_\rho$ as a weighted
grpah then it is a small-set-expander.
</div>

<div class="rmk envbox">**Remark.**
There was some kind of fancy chernoff-like bound based on this.
</div>

