<h1 id="the-probabilistic-method">The Probabilistic Method</h1>
<h3 id="preface">preface</h3>
<p>I am going to try to read “The Probablistic Method” by Noga Alon and Joel H. Spencer. The Probablistic Method, pioneered by Erdos, is a really interesting way to think about combinatorics problems. Here is a high level overview of how proofs by the probabilistic method go</p>
<hr />
<blockquote>
<p>Consider a random thing<br />
Break the thing up into simple sub-things<br />
Compute something on the sub-things<br />
Combine the sub-things together to get<br />
Pr[thing is good] &gt; 0<br />
Thus, there must be some thing that is good.</p>
</blockquote>
<hr />
<p>The approach is often pretty non-constructive but sometimes it can be made constructive.</p>
<h5 id="resonable-example">resonable example</h5>
<div class="rmk envbox">
<p><strong>Remark.</strong> Yup I’m putting math in the preface to my blog! I think this is a good idea. It gives you a bit of a better idea what this blog is about. It’d be kind of weird to keep reading for hours before you even know what the probabilistic method is!</p>
</div>
<p>Let <span class="math inline">\(\mathcal{F}\)</span> be an intersecting family of sets Let <span class="math inline">\(2k \le n\)</span> and suppose <span class="math inline">\(\mathcal{F}\)</span> is an intersecting family of <span class="math inline">\(k\)</span> element subsets of an <span class="math inline">\(n\)</span> set</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> <strong>“Erdos-Ko-Rado Theorem”</strong> <span class="math display">\[|\mathcal{F}| \le {n-1 \choose k-1}\]</span></p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> This is tight! It is achievable by the “sunflower configuration”, where you choose all sets that intersect with <span class="math inline">\(0\)</span></p>
</div>
<div class="lem envbox">
<p><strong>Lemma.</strong>  can contain at most k sets of the form s+[k]</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> fix some set <span class="math inline">\(t+[k]\)</span> in <span class="math inline">\(\mathcal{F}\)</span>. To intersect <span class="math inline">\(t+[k]\)</span> the set has to be like <span class="math inline">\(t-i+[k]\)</span> or <span class="math inline">\(t+i+[k]\)</span> for some <span class="math inline">\(0 &lt; i &lt; k\)</span>. There are <span class="math inline">\(2(k-1)\)</span> such sets. We can pair off sets of the form <span class="math inline">\(s+[k]\)</span> with sets of the form <span class="math inline">\(s+k+[k]\)</span>. Because <span class="math inline">\(2k \le n\)</span> these sets are disjoint. Hence, <span class="math inline">\(\mathcal{F}\)</span> contains at most one of them. Hence <span class="math inline">\(\mathcal{F}\)</span> contains at most <span class="math inline">\(2(k-1)/2 + 1 = k\)</span> of these types of sets.</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> (proof of Erdos-Ko-Rado Theorem)</p>
<p>Choose a random permutation <span class="math inline">\(\pi\)</span> of <span class="math inline">\([n]\)</span>. Choose a random <span class="math inline">\(i \in [n]\)</span>. Conditioning on <span class="math inline">\(\pi\)</span>, the probability of <span class="math inline">\(\sigma(i+[k]) \in \mathcal{F}\)</span> is at most <span class="math inline">\(k/n\)</span> by the Lemma (relabel stuff). The probability of A  is of course equal to <span class="math inline">\(|\mathcal{F}| / {n \choose k}\)</span>. Thus we have <span class="math display">\[\frac{|\mathcal{F}|}{{n \choose k}} \le \frac{k}{n}.\]</span> Hence <span class="math display">\[|\mathcal{F}| \le {n \choose k} \frac{k}{n} = {n-1 \choose k-1}.\]</span></p>
</div>
<h5 id="story">story</h5>
<div class="rmk envbox">
<p><strong>Remark.</strong> This part is a somewhat soggy and crumbly “personal motivation for doing this story thing”. Consider skipping straight to my post on Chapter 0, or even Chapter 1. Nevertheless I feel obligated to write an at least somewhat compelling preface, because I like to read prefaces. So yeah, whatever. If the real numbers are complete, then I better be complete in my blogging.</p>
</div>
<p>I want to read this book because I believe that it contains some really elegant math, and I think math is super cool. The first half of my senior year wasn’t super fun for me; I was super busy and doing a lot of things that I didn’t find very interesting. Thinking back on that time, the most prominent positive memory is of math. In particular, I was taking a functional analysis class. Twice a week, every week, I would rush out of school and jump on my bike to ride over to a local university (Harvard) where I was listening to the lectures. I left behind all the baggage of tasks performed grudgingly and was immersed in theland of infinite dimensional vector spaces and bounded linear functionals for a magnificent hour and fiveteen minutes. On weekends and whatever other spare moments of time that I found I worked on the psets for the class, which usually consisted of a couple really interesting and often pretty challenging proofs.</p>
<p>One time when I was biking there it rained (really hard). Prior to the bike ride I was annoyed because of “school and stuff”. I was completely soaked by the time I got there, and pretty cold too (Note: some people have pointed out that I should have taken the bus instead of biking, especially when the weather was sub-optimal. This is a good point. Also note that I am not advocating for biking in the rain, especially when it is cold. In fact this is kind of a dumb thing to do.). Yet, seemingly strangely I felt very happy while biking. I thought about it a bit and came up with this list of things that I think made my experience with functional analysis so great:</p>
<ul>
<li>I was learning it purely for fun (in particular, I didn’t tell my school that I was taking this class, and didn’t do anythign with my grade)</li>
<li>An incredibly enthusiastic professor guided us through the definitions and proofs from the book, with many fun examples (on a black board!)</li>
<li>The content had some really interesting and non-trivial, while still elegant, proofs.</li>
<li>I was able to share the novel math I was learning with my friends. I did this a lot while walking to and from school, and I also gave a talk to our math team about it and even <a href="https://awestover.github.io/skyspace/functional_analysis/">wrote a (short) blog post about it!!!</a></li>
</ul>
<p>Anyways, this story does have a point. It just is going to take me a minute to get to it.</p>
<p>The point is: I love math.</p>
<p>OK, you might say, I probably could have guessed that. What’s with the long story?</p>
<p>I love math, But keeping a consistent schedule, even at doing things that you love, is hard (for me at least), especially if the thing in question is challenging. Other stuff will innevitably try to get in the way. That’s where this blog comes in. I’m going to write a blog post regularly about the chapter of the Probabilistic Method that I’ve been reading. Having a blog means that with <strong>non-zero probability</strong> some people will be sad if I don’t read for a week. It also gives me a very nice record of the things I’ve learned, and will look very cool (I plan to draw lots of pictures). So that’s my selfish rationale for writing this blog.</p>
<p>Furthermore, maybe this blog can teach you some cool combinatorics too! I will do my best to make my explanations compelte and understandable to people who haven’t been reading the book. In particular I will introduce any combinatorial objects that it talks about. Sharing math with others is something I find super fun, so I hope you enjoy.</p>
<p>If you’re interested in reading this, please don’t be put off by all the fancy words and stuff, or by personal feelings of inadequacy. I didn’t know what a “Ramsey number” or a “Hypergraph” was before reading this book either. In actuality these are not too complicated ideas; I hope to be able to convince you of this proposition by drawing some pictures. Some more notes:</p>
<ul>
<li>If you read this and think it’s cool please let me know!</li>
<li>If you read this and are confused about something, also let me know! I’d love to talk about it!</li>
<li>If you read this and think I’ve botched some math somewhere, definitely let me know!</li>
</ul>
<p>A final note to the reader: this blog is going to be somewhat casual, especially in terms of language used, although also sometimes in terms of definitions and proofs. In particular I’m potentially gonna use slang, and exclamations of excitement such as “yo epic” and “now that’s pretty cool” or similar. Also there are going to be a <em>lot</em> of speelling mistakes. I hope neither of these things distract from the mahtematical content of the blog (in fact I suspect the enthusiasm will be helpful).</p>
Really the final note to the reader before starting:
<div class="rmk envbox">
<p><strong>Remark.</strong> <strong>Thank you for reading! (conditional on the existence of you). I hope you find this experience as epic as I have.</strong></p>
</div>
<p>Now we begin our discussion of <strong>THE PROBABILISTIC METHOD</strong>!!!!!!</p>
<h1 id="chapter-0">Chapter 0</h1>
<h3 id="may-13">[[May 13]]</h3>
<p>This is not a chapter in the book. In this post I’m just going to define a bunch of combinatorial objects. Some of them you are likely already familiar with, but some definitions may be new. At least look at the pictures.</p>
<h2 id="some-basic-combinatorial-objects">some basic combinatorial objects</h2>
<div class="defn envbox">
<p><strong>Definition.</strong> A set is an (unordered) collection of distinct objects.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Some nice sets:</p>
<ul>
<li><span class="math inline">\(\mathbb{N}= \{1,2,\ldots, \}\)</span> (natural numbers)</li>
<li><span class="math inline">\(\mathbb{Z}= \{\ldots, -2, -1, 0, 1, 2, \ldots \}\)</span> (integers)</li>
<li><span class="math inline">\(\mathbb{Q}= \{ p/q : p,q\in \mathbb{Z}, q\neq 0 \}\)</span> (rationals)</li>
<li><span class="math inline">\(\mathbb{R}\)</span> is the completion of <span class="math inline">\(\mathbb{Q}\)</span> (reals)</li>
<li><span class="math inline">\(\mathbb{R}^n\)</span></li>
<li><span class="math inline">\(\mathbb{C}\)</span></li>
<li><span class="math inline">\([n] = \{1,2,\ldots, n\}\)</span></li>
<li><span class="math inline">\(\{\{1,2\}, \{1,2,3\}\}\)</span></li>
<li><span class="math inline">\(\{(1,2), (2,3)\}\)</span></li>
</ul>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> You might notice that I didn’t list the ZFC set theory axioms. That’s because</p>
<ul>
<li>this is a blog post on combinatorics</li>
<li>basically all the sets we are going to be dealing with are <strong>finite</strong></li>
<li>I don’t know a lot about set theory</li>
</ul>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A multiset is an unordered collection of possibly not distinct objects</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> some multisets:</p>
<ul>
<li><span class="math inline">\(\{1,2\}\)</span></li>
<li><span class="math inline">\(\{1,1,1,2\}\)</span></li>
</ul>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> An <span class="math inline">\(n\)</span> element list, also called a <span class="math inline">\(n\)</span>-tuple, is an ordered set of elements</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> some lists:</p>
<ul>
<li><span class="math inline">\((1,2,3,4,5)\)</span></li>
<li><span class="math inline">\((5,4,3,2,1)\)</span></li>
</ul>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> An undirected graph is composed of a set <span class="math inline">\(V\)</span> of “vertices” along with a set <span class="math inline">\(E\)</span> of “edges”. Every edge <span class="math inline">\(e \in E\)</span> is composed of 2 vertices, i.e. <span class="math inline">\(e=\{x,y\}\)</span> for vertices <span class="math inline">\(x, y \in V\)</span>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> See graphical depictions of these graphs below. (vertices are represented by dots, edges by lines)</p>
<ul>
<li><span class="math inline">\(P_n\)</span> the path graph with <span class="math inline">\(n\)</span> edges.</li>
<li><span class="math inline">\(C_n\)</span> the cycle graph on <span class="math inline">\(n\)</span> vertices.</li>
<li><span class="math inline">\(K_n\)</span> the complete graph on <span class="math inline">\(n\)</span> vertices</li>
<li><span class="math inline">\(K_{n, m}\)</span> the complete bipartite graph with one part having <span class="math inline">\(n\)</span> vertices, and the other part having <span class="math inline">\(m\)</span> vertices.</li>
<li><span class="math inline">\(W_n\)</span> the wheel graph on <span class="math inline">\(n\)</span> vertices.</li>
<li><span class="math inline">\(St_n\)</span> the star graph on <span class="math inline">\(n\)</span> vertices.</li>
<li><span class="math inline">\(\square_n\)</span> the cube graph in <span class="math inline">\(n\)</span> dimensions.</li>
</ul>
<p>(thanks to <a href="http://people.qc.cuny.edu/faculty/christopher.hanusa/courses/634sp11/Documents/634ch1-2.pdf">this random site</a> for their “dictionary of graphs” )</p>
<p><img src="src/images/chpt0/graph0.png" alt="some graphs" /> <img src="src/images/chpt0/graph1.png" alt="some graphs" /> <img src="src/images/chpt0/graph2.png" alt="some graphs" /></p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A directed graph is a composed of a set <span class="math inline">\(V\)</span> of vertices along with a set <span class="math inline">\(E\)</span> of edges. Here the edges are directed, i.e. they are lists rather than sets. e.g. <span class="math inline">\((x,y) \in E\)</span> for <span class="math inline">\(x,y\in V\)</span> is an edge.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> <img src="src/images/chpt0/graph3.png" alt="a poset :O" /></p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A tournament on <span class="math inline">\(n\)</span> vertices is a orientation of the edges in <span class="math inline">\(K_n\)</span>. That is, for each pair of distinct <span class="math inline">\(x, y \in V\)</span> either <span class="math inline">\((x,y) \in E\)</span> or <span class="math inline">\((y, x) \in E.\)</span></p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> <img src="src/images/chpt0/graph4.png" alt="tournament" /></p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A hypergraph is a set of vertices <span class="math inline">\(V\)</span> along with a family <span class="math inline">\(E\)</span> of subsets of <span class="math inline">\(V\)</span> called edges.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> <img src="src/images/chpt0/graph5.png" alt="hypergraph" /></p>
</div>
<h2 id="some-basic-functions">some basic functions</h2>
<div class="defn envbox">
<p><strong>Definition.</strong> Without getting into measure theory, here’s my shot at defining / describing a random variable.</p>
<p>“The outcome of a random process”</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong></p>
<ul>
<li>A fair coin toss (aka Bernouli random variable with <span class="math inline">\(p=1/2\)</span>)</li>
<li>Flip <span class="math inline">\(100\)</span> coins, count number of heads (aka binomial random variable with <span class="math inline">\(p=1/2\)</span>, <span class="math inline">\(n=100\)</span>)</li>
</ul>
<figure>
<img src="src/images/chpt0/misc0.png" alt="" /><figcaption>coin toss</figcaption>
</figure>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> Probability distribution. For the discrete case these are probability mass functions. In the continuous case we need probability density functions.</p>
<p>Assigns probabilities to events.</p>
<p>Probabilities are non-negative, and should sum/integrate to <span class="math inline">\(1\)</span>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> some pmfs:</p>
<ul>
<li><span class="math inline">\(\Pr(X=k)= 1/n\)</span> for <span class="math inline">\(k \in [n]\)</span>. (uniform distribution on <span class="math inline">\([n]\)</span>)</li>
<li><span class="math inline">\(\Pr(X=k) = p^k (1-p)^{n-k} \binom{n}{k}\)</span> for <span class="math inline">\(k \in 0,1,\ldots, n\)</span> (binomial PMF with parameters <span class="math inline">\(n, p\)</span>)</li>
<li><span class="math inline">\(\Pr(X=k) = \frac{e^{-\mu} \mu^k}{k!}\)</span> for <span class="math inline">\(k=0,1,2,\ldots\)</span> (poisson PMF with parameter <span class="math inline">\(\mu\)</span>)</li>
</ul>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> An event is a subset of the possible things that can happen.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong></p>
<ul>
<li>You flip 2 coins and get at least <span class="math inline">\(1\)</span> head.</li>
<li>You choose a random number uniformly from <span class="math inline">\([0,1]\)</span> and it is at most <span class="math inline">\(0.1415\)</span>.</li>
</ul>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> The expectation of a random variable <span class="math inline">\(X\)</span> is</p>
<p><span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[X] = \sum_{x} x \Pr(X=x)\]</span></p>
<p>this is just “weighted average of outcomes using probabilities as weights”</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Some examples</p>
<ul>
<li>If you flip <span class="math inline">\(100\)</span> coins the expectation of the random variable “number of heads” is <span class="math inline">\(50\)</span></li>
</ul>
</div>
<p>OK, sorry if these definitions are a bit too soggy and non-rigorous for the measure theory enthusiasts / people who know about probability. Also sorry if it is too long and you’re bored now, or if its too short and I forgot to define important things. Luckily you can google stuff. Anyways, see you next chapter!!</p>
<h1 id="chapter-1">Chapter 1</h1>
<h4 id="may-13-1">[[May 13]]</h4>
<p>(yes I’m writing these concurrently. gotta jump start the blog.)</p>
<p>OK!!! We’re going to actually show the probabilistic method in action now, through a very cool example: <strong>Ramsey Numbers</strong>.</p>
<div class="defn envbox">
<p><strong>Definition.</strong> The Ramsey Number <span class="math inline">\(R(a,b)\)</span> is the smallest number of people that must be in a room such that there must be either a subset of <span class="math inline">\(a\)</span> people who <em>all know each other</em> or a subsetof <span class="math inline">\(b\)</span> people who <em>all don’t know each other</em>.</p>
<p>Here are two more “graph-theoretically-technical” ways of saying this.</p>
<p><span class="math inline">\(R(a,b)\)</span> is the minimum <span class="math inline">\(n \in \mathbb{N}\)</span> such that any graph on <span class="math inline">\(n\)</span> vertices must either have an <span class="math inline">\(a\)</span>-clique (i.e. have <span class="math inline">\(K_a\)</span> as an induced subgraph) or have a <span class="math inline">\(b\)</span>-independent set (i.e. have a completely disconnected induced subgraph on <span class="math inline">\(b\)</span> vertices).</p>
<p><span class="math inline">\(R(a,b)\)</span> is the minimum <span class="math inline">\(n\in\mathbb{N}\)</span> such that any <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> with red and blue must have a <span class="math inline">\(K_a\)</span> monochromatic red induced subgraph or a <span class="math inline">\(K_b\)</span> monochromatic blue subgraph.</p>
</div>
<p>Computing <span class="math inline">\(R(a,b)\)</span> is in fact a large open problem in combinatorics. Very few non-trivial values of this function are known.</p>
<div class="ex envbox">
<p><strong>Example.</strong> Let’s compute some trivial values and bounds on <span class="math inline">\(R(a,b)\)</span></p>
<ul>
<li><span class="math inline">\(R(a, b) = R(b, a)\)</span> because if you swap the colors red and blue then its still the same number.</li>
<li><span class="math inline">\(R(1, c) = 1\)</span> because if you have <span class="math inline">\(1\)</span> person, then there is definitely <span class="math inline">\(K_1\)</span> as a subgraph and it’s certainly monochromatic (it has no edges :) )</li>
<li><span class="math inline">\(R(2, c) = c\)</span> because
<ul>
<li>if we color every edge in <span class="math inline">\(K_n\)</span> blue for <span class="math inline">\(n&lt;c\)</span> then there clearly is no monochromatic red <span class="math inline">\(K_2\)</span> or a monochromatic <span class="math inline">\(K_c\)</span> contained in this graph</li>
<li>But, in <span class="math inline">\(K_c\)</span>,
<ul>
<li>Either every edge is blue, in which case there is a monochromatic blue <span class="math inline">\(K_n\)</span></li>
<li>There is a red edge, in which case there is a monochromatic red <span class="math inline">\(K_2\)</span></li>
</ul></li>
</ul></li>
</ul>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Now we are going to compute the only other value of <span class="math inline">\(R(a,b)\)</span> that I know how to compute: <span class="math inline">\(R(3,3)\)</span>.</p>
<p>First, note that <span class="math inline">\(R(3,3) &gt; 5\)</span> by the following picture:</p>
<figure>
<img src="src/images/chpt1/graph0.png" alt="" /><figcaption><span class="math inline">\(R(3,3) &gt; 5\)</span> graph</figcaption>
</figure>
<p>If you look at this graph, you’ll see that there are no monochromatic triangles (<span class="math inline">\(K_3\)</span>’s). Thus <span class="math inline">\(n=5\)</span> is not large enough to guarantee that every <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> has a monochromatic triangle (<span class="math inline">\(K_3\)</span>).</p>
<p>On the other hand though, I claim <span class="math inline">\(R(3,3) \le 6\)</span>.</p>
<p>Here’s why: Consider a coloring of <span class="math inline">\(K_6\)</span> and take some vertex <span class="math inline">\(v\)</span>. <span class="math inline">\(v\)</span> of course has <span class="math inline">\(5\)</span> neighbors. By the pidgeon-hole principle <span class="math inline">\(v\)</span> either has at least <span class="math inline">\(3\)</span> red edged neighbors or at least <span class="math inline">\(3\)</span> blue edged neighbors. WLOG let’s say <span class="math inline">\(v\)</span> has at least <span class="math inline">\(3\)</span> red edged neighbors.</p>
<p>None of these neighbors can be connected to each other by a red edge, or else they would form a red triangle with <span class="math inline">\(v\)</span>! But then we are forced to have a blue triangle! So it’s impossible for <span class="math inline">\(K_6\)</span> to not have a monochromatic triangle.</p>
<figure>
<img src="src/images/chpt1/graph1.png" alt="" /><figcaption><span class="math inline">\(R(3,3) \le 6\)</span> graph</figcaption>
</figure>
<p>Thus <span class="math display">\[R(3,3) = 6.\]</span></p>
</div>
<p>Now I’m going to derive some cool bounds on the Ramsey numbers. First I’ll derive an upper bound. This proof doesn’t use the probabilistic method, but it’s still cool. I read the proof <a href="https://math.mit.edu/~apost/courses/18.204_2018/ramsey-numbers.pdf">here</a>.</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> <span class="math display">\[R(a, b) \le R(a-1,b) + R(a, b-1)\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> It’s actually pretty similar to the <span class="math inline">\(R(3,3) \le 6\)</span> proof.</p>
<p>Let <span class="math inline">\(n = R(a-1,b)+R(a,b-1)\)</span>. Assume for contradiction that there exists a <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> (with red and blue) such that <span class="math inline">\(K_n\)</span> doesn’t have <span class="math inline">\(K_a\)</span> monochromatic red subgrpah or <span class="math inline">\(K_b\)</span> monochromatic blue subgraph.</p>
<p>Fix a vertex <span class="math inline">\(v\)</span>. Let <span class="math inline">\(A\)</span> be the set of neighbors connected to <span class="math inline">\(v\)</span> with red edges, and <span class="math inline">\(B\)</span> be the set of neighbors connected to <span class="math inline">\(v\)</span> with blue edges. There are <span class="math inline">\(n\)</span> total vertices, so <span class="math inline">\(|A|+|B|+1=n\)</span>.</p>
<p>Now consider the induced subgraph on <span class="math inline">\(A\)</span>. By assumption <span class="math inline">\(A\)</span> doesn’t contain a <span class="math inline">\(K_b\)</span> monochromatic blue subgraph. Furthermore, each vertex in <span class="math inline">\(A\)</span> is connected to <span class="math inline">\(v\)</span> by a red edge, so if <span class="math inline">\(A\)</span> has a red <span class="math inline">\(K_{a-1}\)</span> then there is a red <span class="math inline">\(K_a\)</span>, which cannot be either, also by assumption. Thus we have <span class="math inline">\(|A| \le R(a-1, b) -1\)</span>.</p>
<p>By identical reasoning we have that <span class="math inline">\(|B| \le R(a, b-1) -1\)</span>.</p>
<p>However this is problematic: <span class="math display">\[n = |A|+|B|+1 \le R(a-1, b) -1 + R(a,b-1) -1 + 1 = n-1\]</span> a contradiction.</p>
<p>Hence <span class="math inline">\(K_n\)</span> actually must have a monocrhomatic red <span class="math inline">\(K_a\)</span> or monochromatic blue <span class="math inline">\(K_b\)</span>. And thus <span class="math inline">\(R(a,b) \le n\)</span> as desired.</p>
</div>
<div class="cor envbox">
<p><strong>Corollary.</strong> <span class="math display">\[R(a,b) \le \binom{a+b-2}{a-1}\]</span></p>
<p>and in particular <span class="math display">\[R(k, k) \le O\left(\frac{4^{k-1}}{\sqrt{k-1}}\right).\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> The recurrence is obviously binomial coefficients. For the base case use the trivial values of <span class="math inline">\(R(a,b)\)</span> that we computed.</p>
<p>Plugging in <span class="math inline">\(a=b\)</span> we get central binomial coefficients, which can be estimated easily by Stirling’s approximation.</p>
</div>
<p>ok, now what you’ve actually been waiting for <strong>the first proof in the book!! a lower bound on diagonal Ramsey numbers by the probabilistic method.</strong></p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Fix <span class="math inline">\(k\)</span>. Let <span class="math inline">\(n\)</span> be sufficiently small such that <span class="math inline">\(\binom{n}{k}2^{1-\binom{k}{2}} &lt; 1\)</span>.</p>
<p>Then <span class="math inline">\(R(k,k) &gt; n\)</span> (i.e. there is some <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> that doesn’t have any monochromatic <span class="math inline">\(K_k\)</span> induced subgraphs)</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> Let <span class="math inline">\(n\)</span> be as specified. Consider a random <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> with each edge being randomly red or blue with equal probabilities (<span class="math inline">\(1/2\)</span>) and all these random choices being made independently.</p>
<p>For any set of <span class="math inline">\(k\)</span> of the vertices (<span class="math inline">\(S \subset V\)</span> with <span class="math inline">\(|S| = k\)</span>) let the <span class="math inline">\(M_S\)</span> be the event that the induced subgraph on <span class="math inline">\(S\)</span> is monochromatic.</p>
<p>For any <span class="math inline">\(S\)</span> <span class="math display">\[\Pr[M_S] = 2\cdot \frac{1}{2^{\binom{k}{2}}}\]</span> because there are <span class="math inline">\(\binom{k}{2}\)</span> edges in <span class="math inline">\(S\)</span>, and <span class="math inline">\(S\)</span> could be monochromatic red or blue.</p>
<p>By the union bound we have</p>
<p><span class="math display">\[ \Pr\left[ \bigvee_{S\subset V, |S|=k} M_S \right] \le \sum_{S\subset V, |S|=k} \Pr[M_S] = \binom{n}{k} 2^{1-\binom{k}{2}} &lt; 1\]</span> by assumption.</p>
<p>But then the probability that all events <span class="math inline">\(M_S\)</span> do not occur is strictly positive.</p>
<p>Hence for some random <span class="math inline">\(2\)</span>-coloring it must be that all events <span class="math inline">\(M_S\)</span> do not occur.</p>
<p>That is, there is some <span class="math inline">\(2\)</span>-coloring of <span class="math inline">\(K_n\)</span> for which there are no monochromatic <span class="math inline">\(K_k\)</span> induced subgraphs.</p>
</div>
<div class="cor envbox">
<p><strong>Corollary.</strong> <span class="math display">\[R(k,k) &gt; \lfloor 2^{k/2}\rfloor\]</span> for <span class="math inline">\(k \ge 3\)</span>.</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> We claim that <span class="math inline">\(n=\lfloor2^{k/2}\rfloor\)</span> satisfies <span class="math inline">\(\binom{n}{k}2^{1-\binom{k}{2}} &lt; 1\)</span>. Note that <span class="math display">\[\binom{n}{k}2^{1-\binom{k}{2}} \le \frac{1}{k!}\frac{2^{k^2/2}}{2^{k^2/2-k/2 -1}} = \frac{2^{k/2-1}}{k!} &lt; 1\]</span> for <span class="math inline">\(k \ge 3\)</span> because I graphed it.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> Stirling’s approximation says <span class="math display">\[k! \sim \sqrt{2\pi k} (k/e)^k\]</span> (i.e. the ratio of these functions tends towards <span class="math inline">\(1\)</span> as <span class="math inline">\(n\to\infty\)</span>).</p>
</div>
<h1 id="chapter-2">Chapter 2</h1>
<h4 id="may-13-2">[[May 13]]</h4>
<p>(yes again all this is written on the same day. ok writing this much on one day was probably a bad idea. but it was fun so whatever. I did get a little tired by the end, but I think I stopped before the content started suffering.)</p>
<p>Chapter 2 is about Expectation. Specifically the new proof strategy highlighted looks like this:</p>
<hr />
<blockquote>
<p>make some random thing<br />
Compute the expectation of it<br />
there has to be a point where <span class="math inline">\(X \ge \mathop{\mathrm{\mathbb{E}}}[X]\)</span> and where <span class="math inline">\(X \le \mathop{\mathrm{\mathbb{E}}}[X]\)</span></p>
</blockquote>
<hr />
<p>One really nice thing about expectation is that it’s linear. I recently was talking about this with people, and I thought of a really nice picture to go with my usual proof of this fact.</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Expectation is linear That is, if <span class="math inline">\(X, Y\)</span> are random variables and <span class="math inline">\(a \in \mathbb{R}\)</span> is some scalar, then</p>
<p><span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[X+Y] = \mathop{\mathrm{\mathbb{E}}}[X] + \mathop{\mathrm{\mathbb{E}}}[Y]\]</span> and <span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[aX] = a\mathop{\mathrm{\mathbb{E}}}[X]\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> First let’s prove the scalar multiplier thing. It’s basically trivial from the definition: scaling all the outcomes by some amount clearly scales the average by the same amount. More formally we have by the definioin of expectation:</p>
<p><span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[aX] = \sum_{y} y \Pr[aX = y] = \sum_{x} ax \Pr[aX = ax] = a\sum_{x} x \Pr[X = x] = a\mathop{\mathrm{\mathbb{E}}}[X].\]</span></p>
<p>ok so that’s super intuitive. But the fact that the sum of the expectations of <strong>even dependent random variables</strong> is still the expectation of their sum seems counterintuitive to some people at first. Here’s a picture that will make it obvious though.</p>
<figure>
<img src="src/images/chpt2/linearityofexpectation.png" alt="" /><figcaption><span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}[X+Y] =\mathop{\mathrm{\mathbb{E}}}[X] + \mathop{\mathrm{\mathbb{E}}}[Y]\)</span></figcaption>
</figure>
<p>So that’s <em>legendary</em> as they say.</p>
</div>
<p>ok so there’s a couple of problems that I want to share with you now. But I’m kind of tired of writing atm so I’ll just chose my favorite of them</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Let <span class="math inline">\(v_1,\ldots, v_n \in \mathbb{R}^m\)</span> be arbitrary unit vectors. Then there exists <span class="math inline">\(\epsilon_1,\ldots, \epsilon_n \in \{-1,1\}\)</span> such that <span class="math display">\[\left| \sum_{i=1}^n \epsilon_i v_i \right| \le \sqrt{n}\]</span> and there exists <span class="math inline">\(\epsilon_1,\ldots, \epsilon_n \in \{-1,+1\}\)</span> such that <span class="math display">\[\left| \sum_{i=1}^n \epsilon_i v_i \right| \ge \sqrt{n}\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> Choose the <span class="math inline">\(\epsilon_i\)</span> randomly with <span class="math inline">\(\Pr[\epsilon_i=-1] = \Pr[\epsilon_i = +1] = 1/2\)</span> (and indpendently). Let <span class="math display">\[X = \left|\sum_{i=1}^n \epsilon_i v_i\right|^2 \]</span> Note</p>
<p><span class="math display">\[X = \sum_{i,j} \epsilon_i\epsilon_j v_i\cdot v_j \]</span></p>
<p>Let’s compute <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}[X]\)</span>:</p>
<p><span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[X] = \sum_{i,j} \mathop{\mathrm{\mathbb{E}}}[\epsilon_i\epsilon_j] v_i\cdot v_j \]</span></p>
<p>If <span class="math inline">\(i=j\)</span> then <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}[\epsilon_i^2] = \mathop{\mathrm{\mathbb{E}}}[1] = 1.\)</span> Else, <span class="math inline">\(\epsilon_i, \epsilon_j\)</span> are independent, so <span class="math inline">\(\mathop{\mathrm{\mathbb{E}}}[\epsilon_i \epsilon_j] = \mathop{\mathrm{\mathbb{E}}}[\epsilon_i] \mathop{\mathrm{\mathbb{E}}}[\epsilon_j] = 0\)</span></p>
<p>Overall we have <span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[X] = \sum_{i} v_i\cdot v_i = n \]</span></p>
<p>There must be choice of <span class="math inline">\(\epsilon_i\)</span> so that <span class="math inline">\(X\ge \mathop{\mathrm{\mathbb{E}}}[X]\)</span> and so that <span class="math inline">\(X \le \mathop{\mathrm{\mathbb{E}}}[X]\)</span>.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> Furthermore, if you choose the <span class="math inline">\(\epsilon_i\)</span> greedily, it works.</p>
<p>Let’s say that we are trying to get the resulting vector <span class="math inline">\(\sum_i \epsilon_i v_i\)</span> to be far from the origin. Greedily choosing them means you flip the vector so that it points in roughly the same directino as the partial sum so far. i.e. make the dot-product <span class="math display">\[\epsilon_s v_s \cdot \left( \sum_{i=1}^{s-1} \epsilon_i v_i \right) \ge 0.\]</span></p>
<p>In the worst case for the vector sum being big this dot product is always <span class="math inline">\(0\)</span>. Then we are kind of spiralling around the origin rather than exploding out. But regardless, even in this trash case we’re good! Here’s a picture showing that greed is good and that even in the trash case we’re rolling.</p>
<p><img src="src/images/chpt2/bigvecsum.png" alt="big sum" /> <img src="src/images/chpt2/rootn.png" alt="adverserial case is not so bad" /></p>
</div>
<p>I’ll try the exercises and put any cool ones I solve here (also for week 1).</p>
<h1 id="chapter-3">Chapter 3</h1>
<h4 id="coming-no-later-than-friday-may-22">[coming no later than Friday May 22]]</h4>
<p>dang it!!! I’m so sorry <span class="citation" data-cites="my_dedicated_fanbase">@my_dedicated_fanbase</span>. I totally forgot about this and stuff. In my defense I was at a hackathon stayed up till 4:30am, and I’ve also been binge-rereading Mistborn (3 700+ page books in 3 days? oops). Agh this blog is falling apart! I’ve done like one of the homework problems so far. aggghhhhh. OK, I’m gonna do better in the future. Anyways, I’m gonna read a bit and go to bed, but tomorrow I really legitamitely will be trying the homework problems and doing some reading. cya!</p>
<p>Update number 2: again, I didn’t get to doing this. I’ve done a bit more of the homework now, but it’s really intense. Honestly I might go and read a different book… I do really want to read that generatingfunctionology book, and I think I can do more of the exercises. I’ll keep trying on the probabilistic method though. I’m not having trouble understanding the proofs, it’s creating them that’s the problem. lol. Anyways, hopefully I can get chapter 3 out soon.</p>
<p>update number 3: ok this section is really coming soon. for real now! I convinced a couple of people to join a little club to read this book with me which’ll be super helpful in terms of reminding me to read :). And just super fun in general.</p>
<p>OK let’s go.</p>
<p>Here’s the big idea for this week:</p>
<hr />
<blockquote>
<p>Random structures are pretty good<br />
But often it turns out that by altering a random structure<br />
you can get somehting even better than what you started with!<br />
This is called an <strong>alteration</strong></p>
</blockquote>
<hr />
<p>This is maybe best described by example:</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Consider the ramsay number <span class="math inline">\(R(k,k)\)</span>. For any integer <span class="math inline">\(n\)</span>, <span class="math display">\[R(k, k) &gt; n - \binom{n}{k}2^{1-\binom{k}{2}}.\]</span></p>
</div>
<p>This turns out to be better than the method I originally talked about way back in Chapter 1! In particular we get</p>
<div class="cor envbox">
<p><strong>Corollary.</strong> <span class="math display">\[R(k,k) &gt; \frac{1}{e}(1+o(1))k2^{k/2}\]</span></p>
</div>
Wheras the old one can’t be better than
<div class="cor envbox">
<p><strong>Corollary.</strong> <span class="math display">\[R(k,k) &gt; \frac{1}{e\sqrt{2}}(1+o(1))k2^{k/2}\]</span></p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> I actually just showed <span class="math inline">\(R(k,k)&gt;2^{k/2}\)</span>, but if I cared more about the exact asymptotics apparenly that’s what the asymptotics come out to.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> Actuall asymptotics aren’t important at all, it’s the method that’s important.</p>
</div>
So let’s prove it!
<div class="pf envbox">
<p><strong>Proof.</strong> Randomly color a graph on <span class="math inline">\(n\)</span> vertices. Let <span class="math inline">\(X\)</span> be the random variable “number of monochromatic <span class="math inline">\(K_k\)</span> subgraphs”. By linearity of expeectation <span class="math display">\[\mathop{\mathrm{\mathbb{E}}}[X] = \binom{n}{k} 2^{1-\binom{k}{2}}.\]</span> Of course there is some coloring where <span class="math inline">\(X \le \mathop{\mathrm{\mathbb{E}}}[X]\)</span>. Pick such a coloring, and remove a vertex from every monochromatic <span class="math inline">\(K_k\)</span>. Of course this new graph has now monochromatic <span class="math inline">\(K_k\)</span>, we just destroyed them all! But the new graph has at least <span class="math display">\[n-\binom{n}{k} 2^{1-\binom{k}{2}}\]</span> vertices, hence the desired claim.</p>
</div>
<h1 id="chapter-4">Chapter 4</h1>
<h1 id="chapter-5">Chapter 5</h1>
<h1 id="chapter-6">Chapter 6</h1>
<h1 id="chapter-7">Chapter 7</h1>
<h1 id="chapter-8">Chapter 8</h1>
<h1 id="the-end">The End</h1>
