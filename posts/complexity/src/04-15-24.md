{title}
random coloring
{contents}

{description}
For my stochastic processes final project I'm reading a paper
about understanding the solution geometry of random coloring
instances. The paper is:
Dimitris Achlioptas, and Amin Coja-Oghlan. "Algorithmic barriers from phase transitions." 2008 49th Annual IEEE Symposium on Foundations of Computer Science. IEEE, 2008.
I think it's quite neat. 
In this post I will organize some thoughts that I had after
reading the proof sketches.
{body}

# Introduction
To introduce the subject of the paper we begin with the
illustrative example of $k$-coloring a random graph.

The random $k$-coloring problem is defined as follows:

> Let $G$ be a random graph with average degree $d$. Is it possible to properly $k$-color the vertices of $G$?

beg rmk
Throughout the note we will use the "configuration model" of
random graphs: namely, we randomly sample a graph from the set of
all graphs with $nd/2$ edges.
However, morally this is quite similar to an Erd\"os-Renyi graph
with the same edge density.
end rmk

The answer to this existential problem is, that there is a
threshold at $d=2k\ln k$. 

beg prop
If $d> (2+\eps)k\ln k$ then the answer
is almost certainly no [TODO: prove].
On the other hand, a second moment method calculation [TODO: do
it] shows that if $d<(2-\eps)k\ln k$ then with probability
$1-o(1)$ [TODO: is the probability expo good?] $G$ is
$k$-colorable.
end prop
beg pf
The proof of existence of a solution is non-constructive: we use
the second moment method.
end pf

A closely related algorithmic question is to give an efficient
algorithm for finding a $k$-coloring of a random graph.
The state-of-the-art for this problem is:
beg prop
If $d<k\ln k$ then there is an efficient algorithm for
$k$-coloring $G$.
end prop
beg pf
The algorithm is as follows:
```
while not all vertices are colored:
  Let v be a vertex with the fewest remaining choices for its color
  Assign v a random available color
```
[TODO: prove that this works]
end pf

Let the **algorithmic threshold** denote the largest edge density
where we have efficient algorithms for $k$-coloring.
Let the **existence threshold** denote the largest edge density
where we are guaranteed (with good probability) that a
$k$-coloring exists.
Note that there is a gap between the algorithmic threshold and
the existence threshold.
This is a quite general phenomenon across many CSPs; for instance
it also occurs for $k$-SAT.
Achiloptas and Coja-Oghlan's goal in this paper is to provide an
explanation of the gap between these thresholds. They do so by giving a
description of the solution space geometry, and showing that this
space undergoes a dramatic change when we cross the threshold
below which we have efficient algorithms for $k$-coloring.

First we define what we mean by solution space geometry, and
describe qualitatively the phase transition that occurs.
The space of $k$-colorings is simply $[k]^{n}$.
We can think of this as a "landscape".
The **height** in the landscape corresponds to the number of violated
constraints (i.e., monochromatic edges).
The **height** of a path between two colorings is the largest
height at any coloring along the path.
The **distance** between two colorings is the number of vertices
that they assign different colors.
Below the algorithmic threshold they show that there is a "giant
ball" of solutions: this ball is large, and it is easy to move between
solutions, in the sense that starting from a given solution there
is a nearby solution that you can walk to along a low height path.
In contrast, above the algorithmic threshold (but still below the
existence threshold so that solutions exist) the solution space
**shatters** and looks like an "error correcting code".
More specifically, the solution space transitions to consisting
of an exponential number of regions, none of which are very
large, and such that the regions are very far apart and separated
by large heights (or "energy barriers").

The most important idea in their analysis is a **transfer principle**.
Roughly speaking this principle says that the view of the
landscape from a random valley is basically the same as the view
from a **planted** valley.
In a **planted** instance of random $k$-coloring instead of
uniformly randomly choosing a graph $G$ of appropriate average
degree, we first fix a coloring $\sigma\in [k]^{n}$ and then
select $G$ from amongst graphs with the appropriate average
degree which are properly colored by $\sigma$.
Intuitively, if a random coloring instance has a very large
number of solutions on average then adding one more solution
won't change its landscape too much.
However, reasoning about the planted model turns out to be *much*
easier than reasoning about the uniform model.

Now we develop these notions more formally. For graph $G$ and
coloring $\sigma\in [k]^{n}$ let $H_G(\sigma)$ count the number
of violated constraints (monochromatic edges) if we color $G$ via
$\sigma$.
Let $S(G)$ denote the set of colorings $\sigma$ with height $H_G(\sigma) = 0$; that is, $S(G)$ is the set of proper $k$-colorings of $G$.
Define the **distance** between two colorings to be the number of
vertices which they assign different colors.
A **cluster** of $G$ is a connected component of $S(G)$, where
two colorings are considered **adjacent** if they have distance
$1$ (differ on a single vertex).
A **region** is a non-empty union of clusters.

Then, the **shattering** phenomenon can be formalized as follows:
beg defn
There exists a partition of $S(G)$ into regions such that:

- The number of regions is at most $\exp(\beta n)$,
- The distance between distinct regions is at least $\zeta n$,
- All paths between distinct regions have height at least $\theta
    n$.
end defn
They show:
beg thm
Shattering happens right above the algorithm threshold for
$k$-coloring.
end thm

Fix graph $G$ and a proper $k$-coloring $\sigma$ of $G$.
We say that a vertex $v$ is **$f(n)$-rigid** (with respect to $G,\sigma$) if every coloring $\tau\in S(G)\setminus \set{\sigma}$ is distance at least $f(n)$ away from $\sigma$.
Otherwise we say that vertex $v$ is **$f(n)$-loose**.
They show:

beg thm
Below the algorithm threshold all variables are loose (with good
probability).
Above the algorithm threshold most variables are rigid.
end thm

# proof sketches

Now we present proof sketches for these theorems.

The most important part of the argument is the **transfer
principle**, i.e., showing that we can understand the view from a
random solution by looking at the view from a planted solution.

To get some intuition for the transfer principle it is useful to
look at a simpler but morally similar case.
beg ex
Let $M$ be a binary matrix with $r$ ones in each row and $c$ ones
in each column. Consider the following two distributions over
ones in the matrix:

1. Sample a random row and then choose a random one in that row.
2. Sample a random column and then choose a random one in that
    column.

Clearly both of these methods for sampling produce the uniform
distribution over ones in $M$.

Now, suppose that we construct matrix $M'$ as follows: 
Fix a number $N\in \N$.
Let $\mathcal{X}$ denote the set of all $k$-colorings of vertex
set $[n]$ where each color is used exactly $n/k$ times.
$\mathcal{X}$ will index the rows of  $M'$.
Let $\mathcal{G}$ denote the set of all graphs $G$ on $nd$
vertices that can be properly $k$-colored in exactly $N$
different ways by colorings $\chi\in \mathcal{X}$.
$\mathcal{G}$ will index the columns of  $M'$.
We put a one in entry $(\chi\in \mathcal{X}, G\in\mathcal{G})$ if
$\chi$ is a proper coloring of $G$.

By symmetry, each row of $M'$ has the same number of ones in it.
By definition each graph $G\in\mathcal{G}$ permits exactly $N$
colorings $\chi\in \mathcal{X}$. Thus, each column of $M'$ also
has the same number of ones in it.

Now, in the same manner as our earlier thought experiment we can
define two equivalent ways of uniformly randomly sampling a $1$
in the matrix.

1. First choose a random graph $G\in \mathcal{G}$ and then sample
   a random coloring $\chi$ from among all $\chi\in \mathcal{X}$ that
   properly color $G$. 
2. First choose a random coloring $\chi\in\mathcal{X}$ and then sample a random
   graph $G$ from among all graphs $G\in\mathcal{G}$ properly colored by $\chi$.

The first option corresponds to considering the view from a
random solution, while the second option corresponds to
considering a view from a planted solution.
In this situation the two distributions defined are identical.

However, this matrix $M'$ is not the distribution we actually
want to sample from.
Rather we are interested in the following distribution:

> Sample a random graph $G$ with
average degree $d<(2-\eps)k\ln k$. Then, sample a random proper
coloring of $G$ (assuming one exists, which it does with good
probability).

This distribution over $G,\chi$ pairs is quite complex however,
and it would be more convenient to study the following
distribution:

> Choose a random coloring $\chi$ and then choose a random graph
$G$ that is properly colored by $\chi$.

Their transfer principle gives a very precise sense in which these
distributions are similar.

end ex

In order to prove the transfer principle they need the following
lemma:
beg lem
Let $G_{n,m}$ be a random graph with $n$ vertices and $m$ edges
and let $S(G)$ denote the number of proper $k$-colorings of $G$. 
Then, with high probability we have
$$ \ln(|S(G_{n,m})|) - \ln \E(S(G_{n,m})) < o(n). $$ 
end lem
beg pf
[TODO: do stuff here]

The proof combines analysis of the second moment $\E[|S(G_{n,m})|^2]$ with theorems of Freidgut concerning sharp thresholds.
end pf

To state the transfer principle we must first formally define the
distributions we are concerned with.
First, define the **uniform model** $U_{n,m}$ as follows:

> Sample a random graph $G$ with $m$ edges, and then sample a
random proper $k$-coloring $\chi$ of $G$ (assuming that one exists).
Output $(G, \chi)$. 

Now, define the **planted model** $P_{n,m}$ as follows:

> Generate a uniformly random $k$-partition $\chi\in [k]^n$.
Choose a uniformly random subset of $m$ edges from amongst the
edges that are not monochromatic under $\chi$. Output $(G,
\chi)$.

Then, the **transfer theorem** says:
beg thm
Let $d = 2m/n  \le (2-\eps)k\ln k$. There exists  $f(n)=o(n)$
such that the following is true.
Let $D$ be any graph property such that $G_{n,m}$ has  $D$ with
probability $1-o(1)$ and let $E$ be any property of pairs
$G,\chi$ where $\chi$ properly colors $G$. 
Suppose that 
$$ \Pr_{P_{n,m}}[(G, \sigma) \text{ has } E \mid G \text{ has } D]\ge 1-\exp(-f(n)). $$ 
Then, 
$$ \Pr_{U_{n,m}}[(G,\sigma) \text{ has } E] \ge 1-o(1). $$ 
end thm

## Loose vars below thresh

notion: list-chromatic num

Algo for finding a nearby solution:
awake, asleep, dead vertices.
subcritical branching process!

Then use the list-chromatic thing to handle the dead guys.

## Rigid vars above thresh

beg thm
There is a big subgraph $G_*$ of $G$ with the property that every
vertex has a lot of neighbors of each other color.
end thm

We use the transfer property to trade for a problem in planted
model.
beg lem
solve planted version
end lem

beg lem
bound on expansion
end lem

beg cor
It's pretty easy to show from the theorem that no vertex in
$G_*$ can have a close coloring.
end cor

## shattering

Now we will prove shattering.
They want some notion of distance that plays nicely with
permuting colors, not exactly sure why but whatever. 

Define $M_{\sigma,\tau}^{ij} = \frac{1}{n} |\sigma^{-1}(i)\cap
\tau^{-1}(j)|$.
Our notion of distance between $\sigma, \tau$ is now gonna be frobenius norm of $M_{\sigma, \tau}$.
Checking for $\sigma = \tau$ it is much bigger than if
$\sigma,\tau$ are "uncorrelated".

beg thm
shattering.
more specifically, 

there are zero solutions at medium distance from $\sigma$.
There are not so many solutions which are pretty close to
$\sigma$.
end thm
It is clear how this allows us to define regions.

ok so to prove the theorem

step 1: transfer principle ofc.

beg lem
step 2: prove in planted model.
end lem
beg pf
I think we just compute expectations.
end pf

gg

