{title}
random coloring
{contents}

{description}
For my stochastic processes final project I'm reading a paper
about understanding the solution geometry of random coloring
instances. The paper is:
Dimitris Achlioptas, and Amin Coja-Oghlan. "Algorithmic barriers from phase transitions." 2008 49th Annual IEEE Symposium on Foundations of Computer Science. IEEE, 2008.
I think it's quite neat. 
In this post I will organize some thoughts that I had after
reading the proof sketches.
{body}

# Introduction
To introduce the subject of the paper we begin with the
illustrative example of $k$-coloring a random graph.

The random $k$-coloring problem is defined as follows:

> Let $G$ be a random graph (I think they use the "configuration model", i.e., sample a random graph based on the number of edges, but this is basically the same as Erdos Renyi) with average degree $d$. Is it possible properly $k$-color the vertices of $G$?

The answer to this existential problem is, that there is a
threshold at $d=2k\ln k$. 

beg prop
If $d> (2+\eps)k\ln k$ then the answer
is almost certainly no [TODO: prove].
On the other hand, a second moment method calculation [TODO: do
it] shows that if $d<(2-\eps)k\ln k$ then with probability
$1-o(1)$ [TODO: is the probability expo good?] $G$ is
$k$-colorable.
end prop
beg pf
The proof of existence of a solution is non-constructive: we use
the second moment method.
end pf

A closely related algorithmic question is to give an efficient
algorithm for finding a $k$-coloring of a random graph.
The state-of-the-art for this problem is:
beg prop
If $d<k\ln k$ then there is an efficient algorithm for
$k$-coloring $G$.
end prop
beg pf
The algorithm is as follows:
```
while not all vertices are colored:
  Let v be a vertex with the fewest remaining choices for its color
  Assign v a random available color
```
[TODO: prove that this works]
end pf

Let the **algorithmic threshold** denote the largest edge density
where we have efficient algorithms for $k$-coloring.
Let the **existence threshold** denote the largest edge density
where we are guaranteed (with good probability) that a
$k$-coloring exists.
Note that there is a gap between the algorithmic threshold and
the existence threshold.
This is a quite general phenomenon across many CSPs; for instance
it also occurs for $k$-SAT.
Achiloptas and Coja-Oghlan's goal in this paper is to provide an
explanation of the gap between these thresholds. They do so by giving a
description of the solution space geometry, and showing that this
space undergoes a dramatic change when we cross the threshold
below which we have efficient algorithms for $k$-coloring.

First we define what we mean by solution space geometry, and
describe qualitatively the phase transition that occurs.
The space of $k$-colorings is simply $[k]^{n}$.
We can think of this as a "landscape".
The **height** in the landscape corresponds to the number of violated
constraints (i.e., monochromatic edges).
The **height** of a path between two colorings is the largest
height at any coloring along the path.
The **distance** between two colorings is the number of vertices
that they assign different colors.
Below the algorithmic threshold they show that there is a "giant
ball" of solutions: this ball is large, and it is easy to move between
solutions, in the sense that starting from a given solution there
is a nearby solution that you can walk to along a low heigh path.
In contrast, above the algorithmic threshold (but still below the
existence threshold so that solutions exist) the solution space
**shatters** and looks like an "error correcting code".
More specifically, the solution space transitions to consisting
of an exponential number of regions, none of which are very
large, and such that the regions are very far apart and separated
by large heights (or "energy barriers").

The most important idea in their analysis is a **transfer principle**.
Roughly speaking this principle says that the view of the
landscape from a random valley is basically the same as the view
from a **planted** valley.
In a **planted** instance of random $k$-coloring instead of
uniformly randomly choosing a graph $G$ of appropriate average
degree, we first fix a coloring $\sigma\in [k]^{n}$ and then
select $G$ from amongst graphs with the appropriate average
degree which are properly colored by $\sigma$.
Intuitively, if a random coloring instance has a very large
number of solutions on average then adding one more solution
won't change its landscape too much.
However, reasoning about the planted model turns out to be *much*
easier than reasoning about the uniform model.

Now we develop these notions more formally. For graph $G$ and
coloring $\sigma\in [k]^{n}$ let $H_G(\sigma)$ count the number
of violated constraints (monochromatic edges) if we color $G$ via
$\sigma$.
Let $S(G)$ denote the set of colorings $\sigma$ with height $H_G(\sigma) = 0$; that is, $S(G)$ is the set of proper $k$-colorings of $G$.
Define the **distance** between two colorings to be the number of
vertices which they assign different colors.
A **cluster** of $G$ is a connected component of $S(G)$, where
two colorings are considered **adjacent** if they have distance
$1$ (differ on a single vertex).
A **region** is a non-empty union of clusters.

Then, the **shattering** phenomenon can be formalized as follows:
beg defn
There exists a partition of $S(G)$ into regions such that:

- The number of regions is at most $\exp(\beta n)$,
- The distance between distinct regions is at least $\zeta n$,
- All paths between distinct regions have height at least $\theta
    n$.
end defn
They show:
beg thm
Shattering happens right above the algorithm threshold for
$k$-coloring.
end thm

Fix graph $G$ and a proper $k$-coloring $\sigma$ of $G$.
We say that a vertex $v$ is **$f(n)$-rigid** (with respect to $G,\sigma$) if every coloring $\tau\in S(G)\setminus \set{\sigma}$ is distance at least $f(n)$ away from $\sigma$.
Otherwise we say that vertex $v$ is **$f(n)$-loose**.
They show:

beg thm
Below algorithm threshold all variables are loose (with good pr).
Above algorithm threshold a most variables are rigid.
end thm

# proof sketches

A convincing example of why the transfer principle is reasonable:
Let $M$ be a matrix. Same number of 1s in each row, same number
of 1s in each col.
Then, sample row and then 1 or col and then 1 is the same distr.

We don't actually need each row and each col to have same number
of 1s, just "close to this" in some sense.

To show: 
property holds wupp for random $G,\sigma$
suffices to show holds whp for planted  $G,\sigma$.

important step:
show number of $k$-colorings of random graph concentrates really
well.

**TRANSFER THEOREM**
beg thm
D: prop that holds for random
E: some prop 

If you can show $\Pr \text{planted}[G,\sigma \text{ has } E | G
\text{ has } D]$ is super close to one then $\Pr
\text{unif}[G,\sigma \text{ has } E]$ is decent.
end thm

## Loose vars below thresh

notion: list-chromatic num

Algo for finding a nearby solution:
awake, asleep, dead vertices.
subcritical branching process!

Then use the list-chromatic thing to handle the dead guys.

## Rigid vars above thresh

beg thm
There is a big subgraph $G_*$ of $G$ with the property that every
vertex has a lot of neighbors of each other color.
end thm

We use the transfer property to trade for a problem in planted
model.
beg lem
solve planted version
end lem

beg lem
bound on expansion
end lem

beg cor
It's pretty easy to show from the theorem that no vertex in
$G_*$ can have a close coloring.
end cor

## shattering

Now we will prove shattering.
They want some notion of distance that plays nicely with
permuting colors, not exactly sure why but whatever. 

Define $M_{\sigma,\tau}^{ij} = \frac{1}{n} |\sigma^{-1}(i)\cap
\tau^{-1}(j)|$.
Our notion of distance between $\sigma, \tau$ is now gonna be frobenius norm of $M_{\sigma, \tau}$.
Checking for $\sigma = \tau$ it is much bigger than if
$\sigma,\tau$ are "uncorrelated".

beg thm
shattering.
more specifically, 

there are zero solutions at medium distance from $\sigma$.
There are not so many solutions which are pretty close to
$\sigma$.
end thm
It is clear how this allows us to define regions.

ok so to prove the theorem

step 1: transfer principle ofc.

beg lem
step 2: prove in planted model.
end lem
beg pf
I think we just compute expectations.
end pf

gg

