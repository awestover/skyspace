\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


A super important notion in linear algebra is that of
**duality**.
Put simply, duality is the following fact:

> there is an isomorphism between vectors and linear functionals

The lay-man's explanation of this is "the dual of a column vector
is a row vector, sometimes also called the transpose".
I don't think this really does the idea justice though.

The way I like to think about it is like this. Let's say that we
have a vector space $V$, with some basis $e_1,\ldots, e_n$. 
Then, the dual space $V^*$ is the set of linear-functionals on $V$. $V^{*}$ has a basis  $\hat{e_1}, \ldots,
\hat{e_n}$ which are the linear functionals that act as follows
on vectors $v=c_1 e_1 + c_2 e_2 + \cdots$: 
 $$\hat{e_i}(v) = c_i.$$

It's kinda interesting. Think about it a bit.

Let's see this in action, to solve the following problem:

<div class="thm envbox">**Theorem.**
$Im A = Im AA^T$
</div>

But actually this isn't the real theorem. The real theorem is:

<div class="thm envbox">**Theorem.**
Let $A: \R^n \to \R^m$, and $A^T : \R^m \to \R^n$. Then 

$$\ker A^{T} \oplus Im A \cong \R^m$$
$$\ker A \oplus Im A^T \cong \R^n.$$

and in-fact, $\ker A^T$ is the orthogonal complement of $Im A$;
similarly $\ker A$ is the orthogonal complement of  $Im A^T$.

</div>

This theorem immediately implies the other theorem via the
following picture
![ink_img009](src/images/ink_img009.png)

<div class="pf envbox">**Proof.**
Say $A^T y = 0$. Then  $y^T A = 0$, so  $y^T A x = 0$ for all $x$, i.e. $y \perp Ax$. 

</div>

