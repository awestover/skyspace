\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


Two choices:

$m$ balls and $n$ bins. 
Each ball is randomly and fully independently assigned two target
bins that it is allowed to be placed in. It chooses the less
crowded of the two. 

The **overload** is the fill of the fullest bin minus $\frac{m}{n}$.

<div class="thm envbox">**Theorem.**
- Overload is $\bigO(\log m)$ whp in $m$ 
- Overload is $\bigO(\log\log n)$ whp in  $n$
</div>
<div class="pf envbox">**Proof.**

Actually this is basically a question that my friend Nathan told
me a [while ago](https://awestover.github.io/skyspace/posts/combinatorics/09-26-23.html).

Here's a really simple argument:
Imagine you're at overload $h$. 
We play the following casino game:

you keep placing balls until you either hit overload $2h$ or hit $0$, at
which time you lose.

Observe that the probability that it is like $3^{h}$ times more
likely that you will be at $0$ than at $2h$.

Now consider the following thought experiment:

You have a game that you win with probability $n^{-100}$.
You play the game $n$ times. What is the probability that you
win? Answer at most $n^{-99}$.

So in summary, this proves that overload is $\bigO(\log m)$.

As for the other result I'm not sure, but will think about it
sometime. 

</div>

