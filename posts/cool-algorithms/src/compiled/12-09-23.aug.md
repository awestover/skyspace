\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


The topic today is taken from [Virginia Williams' MM + Graph Algs lecture notes](https://people.csail.mit.edu/virgi/6.890/). Throughout the post $\omega<2.4$ is the matrix multiplication exponent.
MM will stand for matrix multiplication.

# Cycles versus triangles

<div class="thm envbox">**Theorem.**
Let $k\in \N_{\ge 3}$ be a constant. 
directed/undirected-$k$-cycle detection can be accomplished in $n^{\omega}$ time on
$n$-vertex graphs.
</div>
<div class="pf envbox">**Proof.**
It suffices to prove the theorem for directed graphs. We won't
need to explicitely mention this throughout the proof, but just
note that the adjacency matrices needn't be symmetric. 

For $k=3$ you can just cube the adjacency matrix and check
whether its trace is $0$. This doesn't work for $k>3$ because
powers of the adjacency matrix count walks, i.e., are allowed to
repeat vertices. 

Instead we do color coding!
Color with $k$ colors. 
Make matrices $A_1,A_2,\ldots, A_{k-1}$
where $A_i$ represents the transition from color $i$ vertices to
color $i+1$ vertices. That is, fix some ordering of the vertices
within each color class, and then make the rows of $A_i$ be the
vertices of color $i$ and the columns of $A_i$ be the vertices of
color $i+1$, and place edges if the vertices are adjacent.

Let $B = A_1\cdot A_2\cdots A_{k-1}$; $B$ can be computed in
$n^{\omega}$ time.
$B[u,v]$ counts the number of $k$-vertex paths from $u$ to $v$
whose vertices are colors $1,2,\ldots, k$.

Now, for each $u,v$ check whether $A[v,u]=1 \land B[u,v]>0$. If
the check ever passes then we have found a $k$-cycle.

If the cycle was correctly colored we must find a $k$-cycle in
this manner. 

The coloring succeeds with probability $\frac{1}{k^{k}}\ge
\Omega(1)$.
Taking $\Omega(\log n)$ tries for the coloring lets us succeed at
least once with high probability.

![src/images/graph1.png](src/images/graph1.png)

</div>

> Is this tight? Turns out it is for odd cycles but not for even.

<div class="thm envbox">**Theorem.**
"Even cycles Even Faster" 

1. For all $k$, there is an $n^{2}$ algorithm to detect existence of a $2k$ cycle (and find it, if it exists).
2. There is an $n^{2}$ time algorithm to find the shortest even cycle.
</div>

First I present two simple proofs of the theorem for $k=2$.
Then I present a proof (hopefully correct) that you can do  $n^{2+\frac{1}{k+1}}$.
One day I'll hopefully read their paper and know the proof for
general $k$.

<div class="pf envbox">**Proof.**
1. Common neighbor(x,y): 
  make an $n \times n$ matrix $A$. $A[i,j]$ will store whether we
  have found a common neighbor for $i,j$ so far. 
  If any cell in the matrix ever gets hit twice then we found a
  $4$-cycle.

  What we do is, for each vertex $v$, for each pair of vertices
  in $N(v)$ mark them as having a common neighbor. 
</div>
<div class="pf envbox">**Proof.**
2. wlog its bipartite:
  In particular, take $G=(V,E)$, and form $G'$ by duplicating the
  vertex set to $V\sqcup V'$ and put an edge between  $uv'$ if $uv$ is an edge in $G$.
  Then, if you had a $4$-cycle in $G$ it is converted into a
  $4$-cycle in $G'$. But of course $G'$ is bipartite and only
  a constant-factor larger.
   Then, run BFS-cycle out of each vertex (for depth $2$).
This must terminate fast. 
More precisely, for all vertices in the neighbor-set of one of
your vertices color their left-neighbors. If a left-neighbor gets
colored twice it means you have a $C_4$.
</div>
<div class="pf envbox">**Proof.**
goal: check whether our graph contains a $2k$-cycle
Note: wlog $m\le o(n^{1+\frac{1}{k}})$ or else we are guaranteed to have a
$2k$-cycle

**Case 1:** There exists a high degree vertex, say with degree larger
than $H$ somewhere on the cycle.
There aren't so many vertices like this. It costs $\frac{m}{H} m$
to just BFS out of all the high degree vertices.

**Case 2**: Negation of case 1. i.e., all vertices on the cycle have degree smaller than $H$.
Then we can do BFS a bit more efficiently, in time $n H^{k}$.

Balancing (1) and (2) gives:

$$ \frac{m}{H}m = nH^{k} \implies \frac{m^{2}}{n} = H^{k+1}.$$
Hence $H=(\frac{m^{2}}{n})^{\frac{1}{k+1}}$ is the right choice.

This yields running time $n^{2+\frac{1}{k+1}}$.
Humm, not quite $n^{2}.$ On reflection maybe this is why their
paper is 14 pages not 1 page.

</div>


Now I establish that odd cycle detection does require $n^{\omega}$ time.
First we prove another interesting result:

<div class="thm envbox">**Theorem.**
Let $k$ be an odd constant. Then directed-$k$-cycle is equivalently hard to undirected-$k$-cycle.
</div>
<div class="pf envbox">**Proof.**
We can convert an instance of undirected-$k$-cycle to
directed-$k$-cycle by thinking of each edge $\set{u,v}$ as being
two directed edges $u\to v$ and  $v\to u$.

The other direction is more subtle.
We are given an instance of directed-$k$-cycle.
By color coding we assume that the graph has parts
$V_1,V_2,\ldots, V_k$ and we only consider edges from $V_i\to
V_{i+1}$.
Let this new graph be $G'$.

Let $G''$ be the graph obtained by dropping the directionality on
the edges in $G'$. 

**Claim**: $G''$ has an undirected-$k$-cycle iff colorful $G'$ has
a directed $k$-cycle. 

Proof of claim:
If $G'$ has a cycle then dropping the directionality won't kill
the cycle. 
If the cycle in $G''$ uses a vertex from each of the $k$ parts
$V_i$ then it is clearly a cycle in $G'$. 
Assume for contradiction that there is a cycle in $G''$ that
doesn't use some part $V_i$. But $G''\setminus V_i$ is bipartite,
so it cannot contain an odd cycle. 


![Depictionn of the layered grahp](src/images/graph2.png)

![Why this breaks if k is even](src/images/graph3.png)

</div>

<div class="thm envbox">**Theorem.**
Let $k$ be a constant.
Directed-$k$-cycle is equivalently hard to triangle detection.
</div>
<div class="pf envbox">**Proof.**
We already showed how to solve directed-$k$-cycle with MM. 

Let $G = (V, E)$ be a graph we want to do triangle detection in. 
Make $k$ copies of the vertex set: $V_1,V_2,\ldots, V_k$.
We denote the copies of a vertex $v$ by $v_1,v_2,\ldots, v_k$.

- Connect $u_1\to v_2 \in V_1 \times V_2$ iff $(u,v)\in E(G)$. 
- Connnect $u_k\to v_1 \in V_{k}\times V_1$ iff $(u,v) \in E(G)$
- For each $i\in [2, k-1]$ and each vertex $v\in V$ connect $v_i\to v_{i+1}\in V_i \times V_{i+1}$.

  A $k$-cycle in this new graph corresponds to a triangle in the
  original graph.

</div>

# Girth

**GIRTH**: length of shortest cycle

### $1.5$-approx in $n^2$ time

**EDIT: I've almost certainly misunderstood this algorithm and
what's written below is likely false. In "Subquadratic time
approximation algorithms for the girth" Williams actually claims
a $n^{5/3}$ time $2$-approx that is almost a $1.5$-approx but
bottlenecked by the triangle case.**
TODO: read this paper.

<div class="thm envbox">**Theorem.**
**Theorem**: you can $1.5$-approximate shortest cycle in $n^{2}$ time.
That is, you either 

- if any cycle of length $\le g$ exists, output a cycle of
    length  $\le 1.5g$
- if no cycle of length $\le g$ exists, no guarantee. 
</div>

<div class="rmk envbox">**Remark.**
If you want to turn the decision problem stated above into
actually an algorithm for finding the shortest cycle, then you
can do the standard binary search trick.
</div>

---

<div class="pf envbox">**Proof.**

wlog $|E(G)|\le n^{1.5}$ or else we instantly have a $4$-cycle.

Let $B$ be the ball of radius $\frac{g}{4}$ aroud some point $x$
on the shortest cycle.

**Case 1**: $|B| \ge \sqrt{n}$ 
Then, if we randomly sample a subset $S$ of size  $\sqrt{n}\log n$ we
intersect with $B$ with high probability. 
Imagine we ran BFS-cycle out of $y\in B$. Then we would find a
cycle of length at most $1.5 g$. 
So what we do is run BFS-cycle out of all the points in $S$.
The cost of this is $\sqrt{n} m \le n^{2}$.

**Case 2:** $B$ is pretty small $|B| < \sqrt{n}$ 
Run a BFS out of each point for $\frac{g}{4}$ steps.

Intuitively what you do is basically construct a graph where
vertices are connected if they are connected by a length
$\frac{g}{4}$ path in the original graph. 
The way you compute this new graph is you BFS out of each vertex. 
But now the BFS is better because we know we can
quit if the ball gets larger than $\sqrt{n}$ because we are assuming that we
aren't in case 1.
Then you could run $4$-cycle detection on it. 
Of course that's not really how life works, because that might
accidentally find a path, but apparently this is fixable.

Constructing this graph costs $n\sqrt{n}$. Doing the four-cycle
detection takes $n^{2}$.

By doing both case 1 and case 2 we get a
$1.5$-approximation in $n^{2}$ time.

</div>

---

### A worse algorithm:

<div class="prop envbox">**Proposition.**
2-approx  in $n^2$ time.
</div>
<div class="pf envbox">**Proof.**
Let $G=(V, E)$. 
form a new graph with vertex sets $V, V'$. make an edge $xy' \in G'$
for $x\in V, y'\in V' \iff xy\in E(G)$. So $G'$ is bipartite. 
claim: If G' has a cycle of length $k$ then G has a cycle of length at least $k/2$. 
proof: I brute-forced k=6. It seems like it should be true in general. 

recall: "even cycles even faster": we can find even cycles (even
is redundant because G' is bipartite but whatever) in G' in $n^2$ time.

</div>

<div class="rmk envbox">**Remark.**
this is strictly worse in every way (except maybe
simplicity) than the $1.5$-approx in $n^{2}$ time proved above. 
</div>

### $4$-approx in $n^{2-1/9}$ time

<div class="thm envbox">**Theorem.**
$4$-approx in $n^{2-1/9}$ time
</div>
<div class="pf envbox">**Proof.**
PoC: if $G$ contains a triangle we want to output a cycle of
length at most $12$. Else, we provide no guarantees.

I'll just do the PoC. But I'm pretty sure stuff should work out strictly
better if the min cycle we are worrying about is larger.

If $m\ge n^{\frac{7}{6}}$ then it's probably really easy to find
a $12$-cycle. So lets assume this is not the case, i.e., $m\le n^{\frac{7}{6}}$.
Now, we do the high-degree low-degree business. 
That is, let $H$ be the high-degree threshold. There are at most
$\frac{m}{H}$ high-degree vertices, so BFS-ing over all of these
costs at most $\frac{m^{2}}{H}$. 
For low-degree vertices we do fancy BFS where we ignore
high-degree vertices. This costs $nH^{2}$ (two levels of BFS for
fiding triangles.)
Balancing this gives:
$$\frac{m}{H}m = nH^{2}  \implies H = (m^{2} / n)^{\frac{1}{3}}
 = n^{\frac{4}{9}}.$$

Then the cost is $nH^{2} = n^{2-\frac{1}{9}}.$
</div>


### additive $1$-approximation for girth in $n^2$ time

<div class="thm envbox">**Theorem.**
Given a graph $G$ of girth $g$ we will find a cycle of length at
most $g+1$ in time $O(n^{2})$.
Futhermore, if $g$ is even the cycle we find will actually be of
length $g$.
</div>
<div class="pf envbox">**Proof.**
Algorithm: BFS-Cycle out of every vertex.
Run time: $O(n^{2})$.
</div>

### Exact Algorithm for Girth in $n^{\omega}$ time

<div class="thm envbox">**Theorem.**
Exact Algorithm for Girth in $n^{\omega}$ time.
</div>
<div class="pf envbox">**Proof.**
First run the additive $1$-approximation. 

If it outputs a cycle of odd length we know it is equal to the
girth. 
Else, call the length of the ouput cycle $2\ell$. The girth is
either  $2\ell$ or $2\ell-1$.

So, now we would just like to determine whether $G$ has a cycle
of length $2\ell-1$. At the beginning of this blog post we showed
how to solve this with $2\ell-2$ matrix multiplications.
But that's not going to cut it here, we don't really have a bound
on $\ell$.

Here's how we construct a triangle-detection instance:
Make a new graph $G'$.
Place $G$ in $G'$. Then create copies of the vertices. Connect
$v\in V(G)$ and copy the copy $w'$ of $w\in V(G)$ if $dist(v,
w)=\ell-1$. We know this distance because of our BFS-ing.

$G'$ has a triangle iff $G$ has an $(2\ell-1)$-cycle.
![ink_img002](src/images/ink_img002.png)

</div>

