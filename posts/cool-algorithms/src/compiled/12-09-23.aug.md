\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


The topic today is taken from [Virginia Williams' MM + Graph Algs lecture notes](https://people.csail.mit.edu/virgi/6.890/). Throughout the post $\omega<2.4$ is the matrix multiplication exponent.
MM will stand for matrix multiplication.

# Cycles versus triangles

<div class="thm envbox">**Theorem.**
Let $k\in \N_{\ge 3}$ be a constant. 
directed/undirected-$k$-cycle detection can be accomplished in $n^{\omega}$ time on
$n$-vertex graphs.
</div>
<div class="pf envbox">**Proof.**
It suffices to prove the theorem for directed graphs. We won't
need to explicitely mention this throughout the proof, but just
note that the adjacency matrices needn't be symmetric. 

For $k=3$ you can just cube the adjacency matrix and check
whether its trace is $0$. This doesn't work for $k>3$ because
powers of the adjacency matrix count walks, i.e., are allowed to
repeat vertices. 

Instead we do color coding!
Color with $k$ colors. 
Make matrices $A_1,A_2,\ldots, A_{k-1}$
where $A_i$ represents the transition from color $i$ vertices to
color $i+1$ vertices. That is, fix some ordering of the vertices
within each color class, and then make the rows of $A_i$ be the
vertices of color $i$ and the columns of $A_i$ be the vertices of
color $i+1$, and place edges if the vertices are adjacent.

Let $B = A_1\cdot A_2\cdots A_{k-1}$; $B$ can be computed in
$n^{\omega}$ time.
$B[u,v]$ counts the number of $k$-vertex paths from $u$ to $v$
whose vertices are colors $1,2,\ldots, k$.

Now, for each $u,v$ check whether $A[v,u]=1 \land B[u,v]>0$. If
the check ever passes then we have found a $k$-cycle.

If the cycle was correctly colored we must find a $k$-cycle in
this manner. 

The coloring succeeds with probability $\frac{1}{k^{k}}\ge
\Omega(1)$.
Taking $\Omega(\log n)$ tries for the coloring lets us succeed at
least once with high probability.

![src/images/graph1.png](src/images/graph1.png)

</div>

> Is this tight? Turns out it is for odd cycles but not for even.

<div class="thm envbox">**Theorem.**
"Even cycles Even Faster" 

1. For all $k$, there is an $n^{2}$ algorithm to detect existence of a $2k$ cycle (and find it, if it exists).
2. There is an $n^{2}$ time algorithm to find the shortest even cycle.
</div>

First I present two simple proofs of the theorem for $k=2$.
Then I present a proof (hopefully correct) that you can do  $n^{2+\frac{1}{k+1}}$.
One day I'll hopefully read their paper and know the proof for
general $k$.

<div class="pf envbox">**Proof.**
1. Common neighbor(x,y): 
  make an $n \times n$ matrix $A$. $A[i,j]$ will store whether we
  have found a common neighbor for $i,j$ so far. 
  If any cell in the matrix ever gets hit twice then we found a
  $4$-cycle.

  What we do is, for each vertex $v$, for each pair of vertices
  in $N(v)$ mark them as having a common neighbor. 
</div>
<div class="pf envbox">**Proof.**
2. wlog its bipartite:
  In particular, take $G=(V,E)$, and form $G'$ by duplicating the
  vertex set to $V\sqcup V'$ and put an edge between  $uv'$ if $uv$ is an edge in $G$.
  Then, if you had a $4$-cycle in $G$ it is converted into a
  $4$-cycle in $G'$. But of course $G'$ is bipartite and only
  a constant-factor larger.
   Then, run BFS-cycle out of each vertex (for depth $2$).
This must terminate fast. 
More precisely, for all vertices in the neighbor-set of one of
your vertices color their left-neighbors. If a left-neighbor gets
colored twice it means you have a $C_4$.
</div>
<div class="pf envbox">**Proof.**
goal: check whether our graph contains a $2k$-cycle
Note: wlog $m\le o(n^{1+\frac{1}{k}})$ or else we are guaranteed to have a
$2k$-cycle

**Case 1:** There exists a high degree vertex, say with degree larger
than $H$ somewhere on the cycle.
There aren't so many vertices like this. It costs $\frac{m}{H} m$
to just BFS out of all the high degree vertices.

**Case 2**: Negation of case 1. i.e., all vertices on the cycle have degree smaller than $H$.
Then we can do BFS a bit more efficiently, in time $n H^{k}$.

Balancing (1) and (2) gives:

$$ \frac{m}{H}m = nH^{k} \implies \frac{m^{2}}{n} = H^{k+1}.$$
Hence $H=(\frac{m^{2}}{n})^{\frac{1}{k+1}}$ is the right choice.

This yields running time $n^{2+\frac{1}{k+1}}$.
Humm, not quite $n^{2}.$ On reflection maybe this is why their
paper is 14 pages not 1 page.

</div>


Now I establish that odd cycle detection does require $n^{\omega}$ time.
First we prove another interesting result:

<div class="thm envbox">**Theorem.**
Let $k$ be an odd constant. Then directed-$k$-cycle is equivalently hard to undirected-$k$-cycle.
</div>
<div class="pf envbox">**Proof.**
We can convert an instance of undirected-$k$-cycle to
directed-$k$-cycle by thinking of each edge $\set{u,v}$ as being
two directed edges $u\to v$ and  $v\to u$.

The other direction is more subtle.
We are given an instance of directed-$k$-cycle.
By color coding we assume that the graph has parts
$V_1,V_2,\ldots, V_k$ and we only consider edges from $V_i\to
V_{i+1}$.
Let this new graph be $G'$.

Let $G''$ be the graph obtained by dropping the directionality on
the edges in $G'$. 

**Claim**: $G''$ has an undirected-$k$-cycle iff colorful $G'$ has
a directed $k$-cycle. 

Proof of claim:
If $G'$ has a cycle then dropping the directionality won't kill
the cycle. 
If the cycle in $G''$ uses a vertex from each of the $k$ parts
$V_i$ then it is clearly a cycle in $G'$. 
Assume for contradiction that there is a cycle in $G''$ that
doesn't use some part $V_i$. But $G''\setminus V_i$ is bipartite,
so it cannot contain an odd cycle. 


![Depictionn of the layered grahp](src/images/graph2.png)

![Why this breaks if k is even](src/images/graph3.png)

</div>

<div class="thm envbox">**Theorem.**
Let $k$ be a constant.
Directed-$k$-cycle is equivalently hard to triangle detection.
</div>
<div class="pf envbox">**Proof.**
We already showed how to solve directed-$k$-cycle with MM. 

Let $G = (V, E)$ be a graph we want to do triangle detection in. 
Make $k$ copies of the vertex set: $V_1,V_2,\ldots, V_k$.
We denote the copies of a vertex $v$ by $v_1,v_2,\ldots, v_k$.

- Connect $u_1\to v_2 \in V_1 \times V_2$ iff $(u,v)\in E(G)$. 
- Connnect $u_k\to v_1 \in V_{k}\times V_1$ iff $(u,v) \in E(G)$
- For each $i\in [2, k-1]$ and each vertex $v\in V$ connect $v_i\to v_{i+1}\in V_i \times V_{i+1}$.

  A $k$-cycle in this new graph corresponds to a triangle in the
  original graph.

</div>

# Girth

**GIRTH**: length of shortest cycle

### $2$-approx in $n^{1.5}$ time

<div class="rmk envbox">**Remark.**
  In "New Subquadratic Approximation Algorithms for the Girth"
  Knudsen talks about Virginia and Roditty's paper. He observes that her
  algorithm outputs a cycle of size $2\ceil{g/2} + 2\ceil{g/4}$
  when the girth is $g$. 
  So technically for $g=3$ this is a $2$-approx. But for larger
  values of $g$ it is essentially a $1.5$-approx. 
  And her algo is indeed $n^{5/3}$.

  Note:
  Knudsen gives a sub-quadratic algorithm that, if the girth is
  $g$, returns a cycle with size at most 
  $$2\ceil{g/2}+2\ceil{\frac{g}{2(k-1)}}\le (1+\eps)g + 3,$$
  for suitably large $k$, although the run time is of course $n^{2-1/k}$.

  So I feel like the barrier to an $o(n^{2})$ $(2-\eps)$-approx
  is really "given a graph with girth $3$, can you find any of 
  a triangle, a square, or a pentagon in subquadratic time?"


</div>

<div class="thm envbox">**Theorem.**
There is an algorithm that, given an $n$-vertex graph $G$ with
girth $g\ge 3$ outputs a cycle of length at most
$$2\ceil{g/2}+2\ceil{g/4}\le 2g,$$
in running time $n^{5/3}$. 
</div>

<div class="rmk envbox">**Remark.**
If you want to turn the decision problem stated above into
actually an algorithm for finding the shortest cycle, then you
can do the standard binary search trick.
</div>

---

<div class="pf envbox">**Proof.**
**CAUTION** I have not been especially careful with the floors
and ceilings in this proof. They are really important if you care about small $g$! Beware.

Let $C$ be a length $g$  cycle in $G$.
Call a ball **huge** if it has size larger than $n^{1/3}$.

**Case 1:** 
Some vertex $v\in C$ has a huge $t$-radius ball, for some $t\le \ceil{g/4}$.
Then, if we randomly sample a subset $S$ of size  $n^{2/3}\log n$ we
intersect with $B$ with high probability. 
Imagine we ran BFS-cycle out of $y\in B$. Then we would find a
cycle of length at most $g+2t \le 2g$. 
So what we do is run BFS-cycle out of all the points in $S$.
The cost of this is $n^{2/3} \cdot n\le n^{5/3}$.

**Case 2:** No vertices on the cycle have huge $\ceil{g/4}$-radius balls. 
Sort the vertices in the graph as $v_1,v_2,\ldots, v_n$ based on how fast their ball gets
huge, i.e., the smallest $k$ such that their radius-$k$ ball is
huge. In particular, make it so that $v_1$'s ball becomes huge
the slowest  and $v_n$'s ball becomes huge the fastest.
Let $H_k$ denote the induced subgraph on $v_1,v_2,\ldots, v_k$.

We do a BFS-Cycle from vertex $k$ in $H_k$ for each $k$, except we stop once we
have visited $n^{2/3}$ vertices. 
Let $k_0$ be the first index when all vertices of $C$ are
contained in $H_{k_0}$. We claim that doing this limited BFS in
$H_{k_0}$ will find a cycle of length at most $2g$.

Note that all vertices $v\in H_{k_0}$  satisfy $|B(v, \ceil{g/4})| \le n^{1/3}$ and thus $|B(v, 2\ceil{g/4})|\le n^{2/3}$.
Thus the BFS-cycle out of $k_0$ will successfully find a cycle of
length like at most $4\ceil{g/4}+1$ ish.

The run time of doing this is going to be $n\cdot n^{2/3}\le n^{5/3}$.

</div>

---

beg thm (Due to Knudsen et al, also from the paper "New
Subquadratic Approximation Algorithms for the Girth".)

There is a (multiplicative) $\bigO(1)$-approx for girth with
running time  $n^{2+1/k}$ for any constant $k$.
end thm
<div class="pf envbox">**Proof.**
We present it for $k=5$ for simplicity. 

We are going to give a $31$-approximation or something.

Do each of the following things:
- Sample a set of $n$ vertices, BFS-Cycle for $n^{1/5}$ steps out
    of each of them.
- Sample a set of $n^{4/5}\log n$ vertices, BFS-cycle for $n^{2/5}$ steps out of each of these vertices.
- Sample a set of $n^{3/5}\log n$ vertices, BFS-cycle for $n^{3/5}$ steps out of each of these vertices.
- Sample a set of $n^{2/5}\log n$ vertices, BFS-cycle for $n^{4/5}$ steps out of each of these vertices.
- Sample a set of $n^{1/5}\log n$ vertices, BFS-cycle for $n^{5/5}$ steps out of each of these vertices.

    Let $C$ be a minimum length cycle.

Let $r_0$ be the minimum $r>0$ such that  $|B(C, \ceil{g/2}(2^{r}-1))|  \le n^{r/5}$.
Then we have that $|B(C, \ceil{g/2}(2^{r_0-1}-1))|  > n^{(r_0-1)/5}$.

We claim that we will find a pretty short cycle when we run the
$r_0$-th itteration of our for-loop. 

By a calculation we find that we will, with high probability, get some vertex $u \in B(C, \ceil{g/2}(2^{r_0-1}-1))$ in the set of size $n^{\frac{6-r_0}{5})} \log n$ that we sample. 
Then if we BFS-cycle out of this dude we get the desired short
cycle. 

</div>

---

### A worse algorithm:

<div class="prop envbox">**Proposition.**
2-approx  in $n^2$ time.
</div>
<div class="pf envbox">**Proof.**
Let $G=(V, E)$. 
form a new graph with vertex sets $V, V'$. make an edge $xy' \in G'$
for $x\in V, y'\in V' \iff xy\in E(G)$. So $G'$ is bipartite. 
claim: If G' has a cycle of length $k$ then G has a cycle of length at least $k/2$. 
proof: I brute-forced k=6. It seems like it should be true in general. 

recall: "even cycles even faster": we can find even cycles (even
is redundant because G' is bipartite but whatever) in G' in $n^2$ time.

</div>

<div class="rmk envbox">**Remark.**
this is strictly worse in every way (except maybe
simplicity) than the $1.5$-approx in $n^{2}$ time proved above. 
</div>

### $4$-approx in $n^{2-1/9}$ time

**TODO**: understand my high-degree low-degree construction better.
in particular, does it give an additive or multiplicative
approximation? presumably multiplicative?


<div class="thm envbox">**Theorem.**
$4$-approx in $n^{2-1/9}$ time
</div>
<div class="pf envbox">**Proof.**
PoC: if $G$ contains a triangle we want to output a cycle of
length at most $12$. Else, we provide no guarantees.

I'll just do the PoC. But I'm pretty sure stuff should work out strictly
better if the min cycle we are worrying about is larger.

If $m\ge n^{\frac{7}{6}}$ then it's probably really easy to find
a $12$-cycle. So lets assume this is not the case, i.e., $m\le n^{\frac{7}{6}}$.
Now, we do the high-degree low-degree business. 
That is, let $H$ be the high-degree threshold. There are at most
$\frac{m}{H}$ high-degree vertices, so BFS-ing over all of these
costs at most $\frac{m^{2}}{H}$. 
For low-degree vertices we do fancy BFS where we ignore
high-degree vertices. This costs $nH^{2}$ (two levels of BFS for
fiding triangles.)
Balancing this gives:
$$\frac{m}{H}m = nH^{2}  \implies H = (m^{2} / n)^{\frac{1}{3}}
 = n^{\frac{4}{9}}.$$

Then the cost is $nH^{2} = n^{2-\frac{1}{9}}.$
</div>


### additive $1$-approximation for girth in $n^2$ time

<div class="thm envbox">**Theorem.**
Given a graph $G$ of girth $g$ we will find a cycle of length at
most $g+1$ in time $O(n^{2})$.
Futhermore, if $g$ is even the cycle we find will actually be of
length $g$.
</div>
<div class="pf envbox">**Proof.**
Algorithm: BFS-Cycle out of every vertex.
Run time: $O(n^{2})$.
</div>

### Exact Algorithm for Girth in $n^{\omega}$ time

<div class="thm envbox">**Theorem.**
Exact Algorithm for Girth in $n^{\omega}$ time.
</div>
<div class="pf envbox">**Proof.**
First run the additive $1$-approximation. 

If it outputs a cycle of odd length we know it is equal to the
girth. 
Else, call the length of the ouput cycle $2\ell$. The girth is
either  $2\ell$ or $2\ell-1$.

So, now we would just like to determine whether $G$ has a cycle
of length $2\ell-1$. At the beginning of this blog post we showed
how to solve this with $2\ell-2$ matrix multiplications.
But that's not going to cut it here, we don't really have a bound
on $\ell$.

Here's how we construct a triangle-detection instance:
Make a new graph $G'$.
Place $G$ in $G'$. Then create copies of the vertices. Connect
$v\in V(G)$ and copy the copy $w'$ of $w\in V(G)$ if $dist(v,
w)=\ell-1$. We know this distance because of our BFS-ing.

$G'$ has a triangle iff $G$ has an $(2\ell-1)$-cycle.
![ink_img002](src/images/ink_img002.png)

</div>

