\newcommand{\one}{\mathbbm{1}}
\newcommand{\bigO}{\mathcal{O}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\img}{Img}
\DeclareMathOperator{\polylog}{\text{polylog}}
\DeclareMathOperator{\poly}{\text{poly}}
\newcommand{\st}{\text{ such that }}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\interior}[1]{ {\kern0pt#1}^{\mathrm{o}} }
\newcommand{\mb}{\mathbf}
\newcommand{\partition}{\vdash}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\eps}{\varepsilon}
\renewcommand{\d}{\mathrm{d}}
\renewcommand{\Re}{\mathrm{Re}}
\renewcommand{\Im}{\mathrm{Im}}

\newcommand{\setof}[2]{\left\{ #1\; : \;#2 \right\}}
\newcommand{\set}[1]{\left\{ #1\right\}}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\contr}{\[ \Rightarrow\!\Leftarrow \]}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}

\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\ang}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


I'm actually super hyped for this chapter, it looks so fancy, and
has "fourier guys". I also just realized that I really want to
understand Fourier analysis. So I will probably take a class on
fourier analysis instead of a complexity theory class. Hard
choice.

Yeah, this chapter is low key my favorite!!
I mean, color coding is still my favorite technique just because
of how useful it is. 
But I really want to thoroughly understand this chapter because
it is super cool.

# PIE

PIE says 

$$|\cap_i A_i| = \sum_{X\subseteq [n]} (-1)^{|X|} |\cap_{j\in X} U\setminus A_j|.$$

Now, the whole "sum over $2^{n}$ subsets" approach might not seem
good. But, let's just do an application.

## num ham cycles


<div class="ex envbox">**Example.**
Fix some vertex $v_0$.
Let $U$ be the set of length $n$ closed walks starting at $v_0$.
Let $A_v$ be the set of length $n$ closed walks starting at
$v_0$ that visit vertex $v$ at least once. 

Then, the number  of hamiltonian cycles in the graph is 

$$\left|\bigcap_v A_v \right|$$

But we can actually compute the terms on the RHS: 
$$\bigcap_{v\in X} U\setminus A_v$$ 
is the number of closed walks of length $n$ starting from $v_0$
in the graph $G-X$.
We can compute this with MM.

So we get a $2^{n}n^{O(1)}$ time algo for computing number of HAM-cycles in a graph. 
Polynomial space, so that's a plus.

</div>

<div class="ex envbox">**Example.**
Ok now we are going to try to do Steiner Tree. In HAM cycle the
key insight was that walks are easier to count than paths.
Here we are going to do something similar: we are going to count
"branching walks" instead of trees.

Branching walks are ordered homomorphic trees.
Basically, you give me a tree with some numbers on it (subject to
the stipulation that numbers on children have to be larger than
numbers on their parents). And then I need to map it's vertices
to the graph. But I'm allowed to do homomorphic stuff.

So we run PIE again, and get the problem of counting the number
of branching walks in certain graphs.

This can be computed with a clever DP:

Let $b_j(a)$ denote the number of length $j$ branching walks
starting from $a$.
As the base case we have $b_0(a) = 1$.
For $j>0$ we have
$$b_j(a) = \sum_{t\in N_G(a)} \sum_{j_1+j_2 = j-1} b_{j_1}(a)
b_{j_2}(t).$$
The neat thing here is that we just peal off a bit of stuff from
the branching walk and recurse-anate the rest.

</div>

<div class="ex envbox">**Example.**
Chromatic Number

Let $k\in O(1)$.
Note that a proper $k$-coloring of $V(G)$ can be thought of as a
cover of $G$ by $k$ independent sets.

To start we compute the numbers of independent subsets of each
vertex set via dynamic programming in $2^{n}n^{O(1)}$ time. Let
$U$ be the set of $k$-tuples of independent sets.

Let $A_v$ be the set of $k$-tuples of independent sets
$I_1,\ldots, I_k$ such that $v\in \bigcup_i I_i$.

Then for any $X\subseteq V$ the quantity $\bigcap_{v\in X} A_v$ is the number of $k$-tuples of
independent sets in $G-X$. We can compute this easily: it's the
number of independent sets in $G-X$ raised to the $k$-th power.

Then we PIE and win.

If you wanna do this in poly space the only solutions ppl know
require $(2+\Omega(1))^{n}$ time.
A $3^{n}n^{O(1)}$ solution is to compute the number of
independent subsets on the fly rather than storing all of them. 

</div>

# Fast Zeta and Mobius Transforms


<div class="defn envbox">**Definition.**
$$(\zeta f)(X) = \sum_{Y\subseteq X} f(Y).$$
$$(\mu f)(X) = \sum_{Y\subseteq X} (-1)^{|X\setminus Y|} f(Y).$$
$$(\sigma f)(X) = (-1)^{|X|}f(X).$$
</div>


<div class="prop envbox">**Proposition.**

$$\zeta = \sigma \mu \sigma$$
$$\mu = \sigma \zeta \sigma$$

</div>

<div class="thm envbox">**Theorem.**
Inversion formula ( this is kinda like PIE)
$\mu\zeta = \zeta\mu = \id.$
</div>

We can view the PIE stuff as doing zeta and mobius transforms. 
Ok, I don't yet get why this is a good idea. But you can do it.

<div class="thm envbox">**Theorem.**
Fast Zeta / Mobius Transform

Can compute all the values of $\zeta f, \mu f$ in  $O(2^{n}\cdot n)$ time.
</div>

# subset convolution and cover product

$$(f*g)(Y) = \sum_{X\subseteq Y}f(X)g(Y\setminus X).$$

cover product:
$$(f\star g)(Y) = \sum_{A\cup B  = Y} f(A)g(B)$$

let's see an application first, because it's hard to see where
we're going.

<div class="ex envbox">**Example.**
Counting colorings via fast subset convolution:

Define $s(X): \mathcal{P}(V)\to \set{0,1}$ to be $1$ iff $X$ is
an independent set.
Then 

$$(s*s*\cdots * s)(X)$$
i.e., $s$ convolved with itself $k$ times is the number of
$k$-colorings of $G[X]$.

</div>


# longest path

looks like they spend most of the tools that they develop working
on longest path problem, to give an alternative to the color
coding stuff.

anyways, I'll read that tomorrow.

