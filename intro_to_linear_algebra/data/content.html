<h1 id="an-introduction-to-linear-algebra">An Introduction to Linear Algebra</h1>
<p>I hope that this little introduction to linear algebra helps you appreciate what it really <strong>is</strong>. I think the first time I saw linear algebra someone was like, “here’s a sysmtem of equations, let’s write it all these coefficients down in a box. Let’s call this box a matrix. yay now we can solve linear systems of equations by just manipulating this box. wooo.” I think this isn’t the best way to go about it. So, while representing linear transformations in terms of matrices is nice, and solving systems of equations is also nice, I am not going to write down <strong>any</strong> matrices today. I’m just going to talk to you about vector spaces and structure preserving maps between vector spaces (aka linear maps). I think that this angle will be a little bit different than other stuff out there, although maybe not. Anyways, I hope you enjoy it!</p>
<h1 id="vector-space">Vector Space</h1>
<p>Well let’s get right to it, no messing around here:</p>
<div class="defn envbox">
<p><strong>Definition.</strong> Roughly speaking, A vector space is a set of objects called <strong>vectors</strong> along with a set of objects called <strong>scalars</strong>, where the notion of addition of vectors and multiplication of vectors by scalars makes sense. Furthermore addition and scaling of vectors play nicely, in particular playing nicely with scalars being added and multiplied.</p>
</div>
<p>Before I make this a bit more precise (e.g. defining nice) I think it’s better that I provide some examples of vector spaces to illustrate what is similar between them.</p>
<div class="ex envbox">
<p><strong>Example.</strong> The most classic of all examples: the set of vectors is <span class="math inline">\(\mathbb{R}^n\)</span>, and the set of scalars is <span class="math inline">\(\mathbb{R}\)</span>. <span class="math inline">\(\mathbb{R}^n\)</span> refers to the set of <span class="math inline">\(n\)</span>-element lists of real numbers. Consider <span class="math inline">\(\mathbb{R}^2\)</span>. Some vectors in <span class="math inline">\(\mathbb{R}^2\)</span> are</p>
<ul>
<li><span class="math inline">\((0, 1)\)</span></li>
<li><span class="math inline">\((1, 0)\)</span></li>
<li><span class="math inline">\((1, 1)\)</span></li>
<li><span class="math inline">\((0, -1)\)</span></li>
<li><span class="math inline">\((5, 6)\)</span></li>
<li><span class="math inline">\((-\pi, e)\)</span></li>
</ul>
<p>We can add vectors via the rule: <span class="math inline">\((x_1,x_2)+(y_1, y_2) = (x_1+y_1, x_2+y_2)\)</span>. We can scale vectors via the rule: <span class="math inline">\(k(x_1,x_2) = (kx_1, kx_2)\)</span>.</p>
<p>This vector space very easily permits visualization, by placing the vectors in the plane.</p>
<p>Vector addition is accomplished gemoetrically by placing vectors “tip to tail” and going from the tip of start of the first vector to the end of the last vector.</p>
<p>Scalar multiplication is accomplished by shrinking/growing the vectors.</p>
<figure>
<img src="data/R2.png" alt="" /><figcaption><span class="math inline">\(\mathbb{R}^2\)</span></figcaption>
</figure>
<p>Some important properties to note about this vector space (these generalize):</p>
<p>Adding <span class="math inline">\((0,0)\)</span> to vectors doesn’t change them: <span class="math inline">\((x,y)+(0,0) = (x,y)\)</span>. Multiplying vectors by <span class="math inline">\(0\)</span> gives to <span class="math inline">\((0,0)\)</span>.</p>
<p>For every vector <span class="math inline">\((a,b)\)</span>, there is another vector, namely <span class="math inline">\((-a,-b)\)</span>, such that <span class="math inline">\((a,b)+(-a,-b) = (0,0)\)</span>.</p>
<p>Let <span class="math inline">\(x, y, z\)</span> be vectors, let <span class="math inline">\(c, k\)</span> be scalars. <span class="math display">\[x+y = y+x.\]</span></p>
<p><span class="math display">\[(x+y)+z = x+(y+z).\]</span></p>
<p><span class="math display">\[c(k(x)) = (ck)x.\]</span></p>
<p><span class="math display">\[(c+k)x = cx + kx.\]</span></p>
<p><span class="math display">\[c(x+y) = cx + cy.\]</span></p>
<p>Another thing that is implicit in this all is the idea of “closure”. <span class="math inline">\(x+y\)</span> needs to be a vector for any vectors <span class="math inline">\(x,y\)</span>, and also <span class="math inline">\(kx\)</span> needs to be a vector for any vector <span class="math inline">\(x\)</span> and any scalar <span class="math inline">\(k\)</span>.</p>
<p>Also, if you don’t know what a field is, don’t worry about it. A field is just a set with multiplication and addition that play really nicely with it. Usually this will be <span class="math inline">\(\mathbb{R}\)</span> for us, although there are some other cool fields (e.g. finite fields, complex numbers).</p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> Now we formally define a vector space. A vector space <span class="math inline">\(V\)</span> over a field <span class="math inline">\(\mathbb{K}\)</span> is a set of vectors <span class="math inline">\(V\)</span> and scalars <span class="math inline">\(\mathbb{K}\)</span> satisfying the following axioms:</p>
<p>Let <span class="math inline">\(0\in V\)</span> denote the <strong>zero-vector</strong> (it’s properties are defined in the axioms below). Let <span class="math inline">\(x,y,z \in V\)</span> let <span class="math inline">\(c,k \in \mathbb{K}\)</span>.</p>
<ul>
<li>“Additive axioms”:
<ul>
<li><span class="math inline">\(x+y=y+x\)</span> (commutativity of addition)</li>
<li><span class="math inline">\((x+y)+z = x+(y+z)\)</span> (associativity of addition)</li>
<li><span class="math inline">\(0+x = x+0 = x\)</span></li>
<li>There is an inverse element <span class="math inline">\(-x\)</span> such that <span class="math inline">\((-x) + x = 0\)</span></li>
</ul></li>
<li>“Multplicative axioms”:
<ul>
<li><span class="math inline">\(0x = 0\)</span></li>
<li><span class="math inline">\(1x = 1\)</span></li>
<li><span class="math inline">\((ck)x = c(k(x))\)</span></li>
</ul></li>
<li>“Distributive axioms”
<ul>
<li><span class="math inline">\(c(x+y) = cx + cy\)</span></li>
<li><span class="math inline">\((c+k)x = cx + kx\)</span></li>
</ul></li>
<li>“Closure axioms”
<ul>
<li><span class="math inline">\(x+y \in V\)</span></li>
<li><span class="math inline">\(cx \in V\)</span></li>
</ul></li>
</ul>
</div>
<p>OK. So probably none of these definitions were very surprising. I’ll give some more examples of vector spaces now, and then we’ll start talking about functions between vector spaces!</p>
<div class="ex envbox">
<p><strong>Example.</strong> The vector space (over the reals) of polynomials with real coefficients <span class="math inline">\(\mathbb{R}[x]\)</span>. Addition and multiplication is defined component-wise, i.e.</p>
<p><span class="math display">\[k \sum p_j x^j = \sum kp_j x^j \]</span></p>
<p><span class="math display">\[\sum a_j x^j + \sum b_j x^j = \sum (a_j + b_j) x^j.\]</span></p>
<p>You can say things like <span class="math display">\[(3x^2 + x + 2) + 5x = 3x^2 + 6x + 2.\]</span> And <span class="math display">\[4(x+1) = 4x+4.\]</span></p>
<p>The <span class="math inline">\(0\)</span>-polynomial satisfies the required conditions, additive inverses are achieved by negating polynomial’s coefficients i.e. <span class="math inline">\(x+1 + (-x-1) = 0\)</span>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Functions <span class="math inline">\(f: \mathbb{N} \to \mathbb{R}\)</span> (vector space over the reals).</p>
<p>Addition is defined point-wise, i.e. </p>
<p><span class="math inline">\(f + g\)</span> is a function such that <span class="math inline">\((f+g)(x) = f(x) + g(x)\)</span> for all <span class="math inline">\(x\in\mathbb{N}\)</span>. <span class="math inline">\(kf\)</span> is a function with <span class="math inline">\((kf)(x) = kf(x)\)</span>.</p>
<p>Some examples are:</p>
<ul>
<li><span class="math inline">\(f(x) = \sqrt{x}.\)</span></li>
<li><span class="math inline">\(f(x) = x\)</span>.</li>
<li><span class="math inline">\(f(x) = \sqrt{2} x.\)</span></li>
<li><span class="math inline">\(f(x) = x^2\)</span>.</li>
<li><span class="math inline">\(f(x) = 0.\)</span></li>
<li><span class="math inline">\(f(x) =\)</span> the number of numbers less than <span class="math inline">\(x\)</span> that are relatively prime to <span class="math inline">\(x\)</span> (i.e.the number of <span class="math inline">\(y&lt;x\)</span> such that <span class="math inline">\(gcd(x,y) = 1\)</span>).</li>
</ul>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> <span class="math inline">\(\mathbb{R}^\mathbb{N}\)</span> (over the reals). This is the space of infinite sequences. Elements include vectors like</p>
<p><span class="math display">\[(1, 1/2, 1/3, 1/4, \ldots)\]</span> and <span class="math display">\[(0,0,0,\ldots).\]</span></p>
<p>Addition and multiplication is defined point-wise:</p>
<p><span class="math display">\[(a_1,\ldots) + (b_1, \ldots) = (a_1+b_1, \ldots)\]</span> <span class="math display">\[k(a_1,\ldots) = (ka_1, \ldots).\]</span></p>
<p>This vector space might be starting to look familiar. Could it be, this is “the same” vector space as the space of functions from the natural numbers to the real numbers? (yes!, more on this later)</p>
</div>
<p>OK I’ll do a couple more quick examples and then start talking about linear transformations. I’m getting there, I promise!</p>
<div class="ex envbox">
<p><strong>Example.</strong> <span class="math inline">\(\mathbb{C}\)</span> over <span class="math inline">\(\mathbb{C}\)</span>. Enough said.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> The space of continuous functions on <span class="math inline">\([0,1]\)</span>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> <span class="math inline">\((\mathbb{Z}/2\mathbb{Z})^n\)</span> the space of binary strings of length <span class="math inline">\(n\)</span>.</p>
<p>I’ll just comment on addition in <span class="math inline">\(\mathbb{Z}/2\mathbb{Z}\)</span> for a second.</p>
<p><span class="math inline">\(1+1 = 0\)</span>, <span class="math inline">\(1+0= 1\)</span>, <span class="math inline">\(0+0 = 0.\)</span> Sound crazy? It’s not. You could interpret <span class="math inline">\(1,0\)</span> as true, false, and then this is NAND (i.e. NOT AND). You could also just think of it as addition mod 2.</p>
<p>Anyways, there are a lot of reasons why you might want the set of binary strings of length <span class="math inline">\(n\)</span>. High quality vector space right there.</p>
</div>
<p>OK, I’m far from being done, but it’s 1:01 (am). wow that rhymed. Anyways, I’m trying to get to bed earlier than normal today, so we’re gonna move on.</p>
<h1 id="linear-transformations">Linear Transformations</h1>
<div class="defn envbox">
<p><strong>Definition.</strong> A linear transformation between vector spaces <span class="math inline">\(V, W\)</span> is a function <span class="math inline">\(T: V\to W\)</span> that plays nicely with vector addition and scaling. In particular <span class="math inline">\(T\)</span> must satisfy:</p>
<p><span class="math display">\[T(x+y) = T(x) + T(y)\]</span> and <span class="math display">\[T(kx) = kT(x)\]</span></p>
</div>
<p>I would probably define linear algebra as “the study of vector spaces and linear maps between them”. but whatever.</p>
<p>Anyways, here’s some examples:</p>
<div class="ex envbox">
<p><strong>Example.</strong> Consider a map <span class="math inline">\(T : \mathbb{R}^2 \to \mathbb{R}^2\)</span> that does <span class="math display">\[(x, y) \mapsto (-y, x) \]</span></p>
<p>This map is linear. It does rotation by 90 degrees counter-clockwise.</p>
<p>Here is a visualization of this map acting on a set of points: <img src="data/rot90.png" alt="data/rot90.png" /></p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Consider a map <span class="math inline">\(T : \mathbb{R}^2 \to \mathbb{R}^2\)</span> that does <span class="math display">\[(x, y) \mapsto (2x, 2y) \]</span></p>
<p>This map is linear. It scales vectors up.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Consider a map <span class="math inline">\(T : \mathbb{R}^2 \to \mathbb{R}^2\)</span> that does <span class="math display">\[(x, y) \mapsto \left(\frac{3}{5} x + \frac{4}{5} y\right)(3/5, 4/5).\]</span></p>
<p>This map does projection onto the line <span class="math inline">\(y=\frac{4}{3}x.\)</span></p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Let <span class="math inline">\(P_n\)</span> be the space of polynomials of degree at most <span class="math inline">\(n\)</span>. The map <span class="math inline">\(T: P_n \to P_n\)</span> <span class="math display">\[T(p) = p&#39;\]</span> (the derivative) is linear.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Let <span class="math inline">\(P_n\)</span> be the space of polynomials of degree at most <span class="math inline">\(n\)</span>. The map <span class="math inline">\(T: P_n \to \mathbb{R}^3\)</span> <span class="math display">\[T(p) = (p(1), p(2), p(3))\]</span> is linear.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> Sometimes we care about non-linear maps between vector spaces. But these are pretty hard to understand. So instead, it is really useful often to use linear approximations of non-linear maps to try to understand them.</p>
<p>The <strong>derivative</strong> of a function is defined to be the best linear approximation to it.</p>
<p>For example, the derivative of the function <span class="math inline">\(f(x,y) = x^2 + y^2\)</span> at the point <span class="math inline">\((a,b)\)</span> is the function <span class="math inline">\(T(\Delta x,\Delta y) = 2a\Delta x + 2b\Delta y.\)</span> Note that <span class="math inline">\(T\)</span> does not take in the actual values <span class="math inline">\(x,y\)</span> but rather <span class="math inline">\(\Delta x\)</span> and <span class="math inline">\(\Delta y\)</span>, which are defined as <span class="math inline">\(x-a, y-b\)</span>. And <span class="math inline">\(T\)</span> outputs the difference from <span class="math inline">\(f(a,b)\)</span>. Thus the approxmiation to <span class="math inline">\(f\)</span> is really <span class="math display">\[f(x,y) \approx T(x-a, y-b) + f(a,b).\]</span> However of course, this function is not linear in <span class="math inline">\(x,y\)</span>! But <span class="math inline">\(T\)</span> is linear in <span class="math inline">\(\Delta x, \Delta y\)</span>.</p>
<p>Note: if you were taught in some single-variable calculus course that the derivative of a function is a number <strong>abandon this notion right now!!!!</strong> The derivative is the best linear approximation to a function. In <span class="math inline">\(\mathbb{R}\)</span> there happens to be an easy way to associate linear functions with numbers (the slope of the function). This doesn’t generalize. It’s way better to think of derrivatives as linear functions that do the best job at approximating the function.</p>
<figure>
<img src="data/lolpic.png" alt="" /><figcaption>data/lolpic.png</figcaption>
</figure>
</div>
<p>Invertible linear maps are a very important type of linear map. For instance, they can be used to define what it means for two vector spaces to be “the same”:</p>
<div class="defn envbox">
<p><strong>Definition.</strong> Two vector spaces are said to be <strong>isomorphic</strong>, written <span class="math inline">\(V \cong W\)</span> if there exists an invertible linear map <span class="math inline">\(\phi : V\to W\)</span> that is onto <span class="math inline">\(W\)</span> (i.e. hits all of <span class="math inline">\(W\)</span>).</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> The vector space of polynomials wtih real coefficients of degree <span class="math inline">\(2\)</span> or less, denote <span class="math inline">\(P_2\)</span>, is isomprphic to <span class="math inline">\(\mathbb{R}^3\)</span>. In particular, we can associate the polynomial <span class="math inline">\(ax^2 + bx + c \in P_2\)</span> with, for instance, <span class="math inline">\((a,b,c) \in\mathbb{R}^3.\)</span> This map is clearly an isomorphism.</p>
</div>
<h1 id="bases">Bases</h1>
<p>Given a set, an interesting question to ask is “how big is this set”. For almost all of the vector spaces we’ve discussed though, the set of vectors is infinite (in fact often uncountably infinite!) so this wouldn’t be a very satisfying thing. However, we can define a notion of largeness of a vector space, <strong>dimension</strong> based on the minimal number of vectors required to be able to reach all the vectors in a space. Now I’ll define this more formally.</p>
<div class="defn envbox">
<p><strong>Definition.</strong> A linear combination of a set of vectors <span class="math inline">\(v_1,\ldots, v_n\)</span> is a vector of the form <span class="math display">\[\sum_{i=1}^n \alpha_i v_i\]</span> for some scalars <span class="math inline">\(\alpha_i\)</span>.</p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A set of vectors <span class="math inline">\(v_1, \ldots, v_n\)</span> is said to <strong>span</strong> a vector space <span class="math inline">\(V\)</span> if any vector <span class="math inline">\(v \in V\)</span> can be expressed as some linear combination of <span class="math inline">\(v_1,\ldots, v_n\)</span>. i.e. there must exist <span class="math inline">\(\alpha_i\)</span> such that <span class="math display">\[v = \sum_{i} \alpha_i v_i.\]</span></p>
</div>
<p>However, we are interested in a <strong>minimal spanning set</strong>.</p>
<div class="defn envbox">
<p><strong>Definition.</strong> A <strong>minimal spanning set</strong> for a vector space <span class="math inline">\(V\)</span> is a finite set of vectors <span class="math inline">\(v_i\)</span> that spans the space, such that if you remove any vector <span class="math inline">\(v_i\)</span> from the set, the resulting set of vectors no longer spans <span class="math inline">\(V\)</span>.</p>
<p>A minimal spanning set is also called a basis.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> A basis for a vector space need not exist. If a vector space does not admit a basis then it is called an <strong>infinite dimensional vector space</strong>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> The vector space of polynomials is infinite dimensional; it clearly admits no basis: imagine it did, then take a polynomial with degree more than the highest degree of the basis elements, this yields a contradiction.</p>
</div>
begin clm We claim that the number of elements in a basis for <span class="math inline">\(V\)</span> is unique. end defn
<div class="pf envbox">
<p><strong>Proof.</strong> Let <span class="math inline">\(V\)</span> have two bases <span class="math inline">\(v_1,\ldots, v_m\)</span> and <span class="math inline">\(w_1,\ldots, w_n\)</span>. We aim to show that <span class="math inline">\(m=n\)</span>.</p>
<p>As <span class="math inline">\(v_i\)</span> spans <span class="math inline">\(V\)</span> we can express each <span class="math inline">\(w_j\)</span> as a linear combination of <span class="math inline">\(v_i\)</span>’s. On the other hand, we can express each <span class="math inline">\(w_j\)</span> as a linear combination of <span class="math inline">\(v_j\)</span>’s.</p>
<p>Assume for contradiction that <span class="math inline">\(m \neq n\)</span>. Without loss of generality <span class="math inline">\(m &lt; n\)</span>.</p>
<p>We inductively create a series of spanning sets:</p>
<ul>
<li><span class="math inline">\(v_1,\ldots, v_m\)</span></li>
<li><span class="math inline">\(w_1, v_2, \ldots, v_m\)</span> this is possible as the previous set was spanning, hence <span class="math inline">\(w_1\)</span> can be written as a linear combination of <span class="math inline">\(v_i\)</span>’s, and it must have a non-zero coefficient, which is on <span class="math inline">\(v_1\)</span> without loss of generality</li>
<li><span class="math inline">\(w_1, w_2, v_3, \ldots, v_m\)</span> by the same logic</li>
<li><span class="math inline">\(\cdots\)</span></li>
<li><span class="math inline">\(w_1,w_2,\ldots, w_m\)</span></li>
</ul>
<p>But this can’t be spanning! It contradicts the minimality of the set <span class="math inline">\(w_1,\ldots, w_n\)</span>, because we shouldn’t be able to remove <span class="math inline">\(w_{m+1},\ldots, w_n\)</span> and still get a spanning set! Hence it is impossible for <span class="math inline">\(m \neq n\)</span>.</p>
<p>And thus the number of elements in a basis is well defined.</p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> We call the dimension of a vector space the number of elements in a basis for it.</p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> A set <span class="math inline">\(v_1,\ldots, v_n\)</span> of vectors is said to be linearly independent if no vector can be made as a linear combination of the other vectors. Equivalently, <span class="math display">\[\sum_i \alpha_i v_i = 0 \,\,\,\, \implies \alpha_i = 0.\]</span></p>
</div>
begin clm An equivalent definition of a basis is <strong>maximal linear independent set of vectors</strong> end clm
<div class="pf envbox">
<p><strong>Proof.</strong> left as an exercise to the reader</p>
</div>
<h1 id="image-and-kernel">Image and Kernel</h1>
<p>OK, now you’re ready to see a very cool result, the <strong>Rank Nullity Theorem</strong>. It is a relationship between two very important sets that give a lot of information about a linear transformation: the image and kernel of the linear transformation.</p>
<div class="defn envbox">
<p><strong>Definition.</strong> A subspace of a vector space <span class="math inline">\(V\)</span> over <span class="math inline">\(\mathbb{K}\)</span> is a subset <span class="math inline">\(M \subset V\)</span> of the vectors that is closed under addition and multiplication.</p>
<p>That is, For any <span class="math inline">\(x,y\in M\)</span> we have <span class="math inline">\(x+y \in M\)</span>, and for any <span class="math inline">\(c \in\mathbb{K}\)</span> we have <span class="math inline">\(cx \in M\)</span>.</p>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> A line through the origin in <span class="math inline">\(\mathbb{R}^2\)</span> or <span class="math inline">\(\mathbb{R}^3\)</span> is a subspace.</p>
<figure>
<img src="data/subspace.png" alt="" /><figcaption>subspace.png</figcaption>
</figure>
</div>
<div class="ex envbox">
<p><strong>Example.</strong> Polynomials of degree at most <span class="math inline">\(2\)</span> that have a zero at <span class="math inline">\(4\)</span> are a subspace of the space of polynomials.</p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> Note that any subspace contains the <span class="math inline">\(0\)</span>-vector as this is necessary to be closed under multiplication.</p>
</div>
<p>Now, as promised, I define some really imporant subspaces.</p>
<div class="defn envbox">
<p><strong>Definition.</strong> The image of a linear transformation <span class="math inline">\(T : V\to W\)</span> is the set <span class="math inline">\(\mathrm{im}(T) = \{T(x) | x\in V\}.\)</span> That is, the set of all vectors “hit” by <span class="math inline">\(T\)</span>; the set of all vectors <span class="math inline">\(y \in W\)</span> so that there exists <span class="math inline">\(x \in V\)</span> with <span class="math inline">\(T(x) = y\)</span>.</p>
</div>
<div class="defn envbox">
<p><strong>Definition.</strong> The kernel of a linear transformation <span class="math inline">\(T: V \to W\)</span> is the set <span class="math inline">\(\ker(T) = \{x \in V | T(x)= 0\}.\)</span> That is, the set of vectors sent to the zero vector.</p>
</div>
<p>I really like the following picture, showing graphically these spaces: <img src="data/imgkerstuff.png" alt="imgkerstuff.png" /></p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Let <span class="math inline">\(T: V\to W\)</span>. <span class="math inline">\(\mathrm{im}(T)\)</span> is a subspace of <span class="math inline">\(W\)</span> and <span class="math inline">\(\ker(T)\)</span> is a subspace of <span class="math inline">\(V\)</span>.</p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> Take <span class="math inline">\(x,y \in \mathrm{im}(T)\subset W\)</span>, <span class="math inline">\(c\)</span> a scalar. Then there must be <span class="math inline">\(a,b \in V\)</span> with <span class="math inline">\(T(a) = x, T(b) = y\)</span>. Then <span class="math display">\[T(a+cb) = T(a)+cT(b) = x+cy.\]</span> So <span class="math inline">\(x+cy \in \mathrm{im}(T).\)</span> Hence <span class="math inline">\(\im(T)\)</span> is a subspace of <span class="math inline">\(W\)</span>, as it is closed under both scaling and addition.</p>
<p>Now take <span class="math inline">\(x, y\in \ker(T) \subset V\)</span>, <span class="math inline">\(c\)</span> a scalar.</p>
<p><span class="math display">\[T(x+cy) = T(x) + cT(y) = 0+ c0 = 0+0 = 0.\]</span> Hence <span class="math inline">\(\ker(T)\)</span> is a subspace of <span class="math inline">\(V\)</span>, as it is closed under both scaling and addition.</p>
</div>
<p>The Rank Nullity Theorem is a relationhsip between these subspaces, which I believe is <strong>“deep stuff”</strong>. I’ll state it now, but we’ll need one more idea before the proof.</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> Let <span class="math inline">\(T: V \to W\)</span> be a linear map. Then <span class="math display">\[\dim\mathrm{im}(T) + \dim \ker T = \dim V.\]</span></p>
</div>
<div class="rmk envbox">
<p><strong>Remark.</strong> <span class="math inline">\(\dim \mathrm{im} T\)</span> is called the “rank” of <span class="math inline">\(T\)</span>, and <span class="math inline">\(\dim \ker T\)</span> is called the “nullity” of <span class="math inline">\(T\)</span>.</p>
</div>
<p>Before proving this, we need a really cool idea: Quotient Spaces!!!</p>
<div class="defn envbox">
<p><strong>Definition.</strong> Let <span class="math inline">\(V\)</span> be a vector space, and let <span class="math inline">\(M \subset V\)</span> be a subspace of <span class="math inline">\(V\)</span>. Then the quotient space <span class="math inline">\(V/W\)</span> (pronounced “<span class="math inline">\(V\)</span> mod <span class="math inline">\(W\)</span>”) is defined as <span class="math display">\[V/W = \{W+x | x \in V\}.\]</span></p>
</div>
<p>Now we prove the following key fact:</p>
<div class="thm envbox">
<p><strong>Theorem.</strong> (First Isomorphism Theorem)</p>
<p>Let <span class="math inline">\(T: V\to W\)</span>, then <span class="math display">\[V/\ker T \cong \mathrm{im} T\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> Consider <span class="math inline">\(x \in V/\ker T\)</span>. Let <span class="math inline">\(x = z+\ker T\)</span> for arbitrary <span class="math inline">\(z\in x\)</span>. Note that for any <span class="math inline">\(y \in x\)</span>, <span class="math inline">\(T(y) = T(z).\)</span> Hence it makes sense to say <span class="math inline">\(T(x) = T(z)\)</span>. We claim that <span class="math inline">\(\phi(z+\ker T) = T(z)\)</span> is an isomorphism between <span class="math inline">\(V/\ker T\)</span> and <span class="math inline">\(\mathrm{im}(T)\)</span>. First note that <span class="math inline">\(\phi\)</span> is well defined because regardless of the chosen representative <span class="math inline">\(z \in x\)</span>, <span class="math inline">\(T(z)\)</span> is the same.</p>
<p>To show that <span class="math inline">\(\phi\)</span> is invertible we must show that it is one-to-one (doesn’t map different values to the same output) and also that it is onto (maps to each element of the codomain).</p>
<p>First we show <span class="math inline">\(\phi\)</span> is one-to-one. If <span class="math inline">\(T(x) = T(y)\)</span> then <span class="math inline">\(T(x-y) = 0\)</span> so <span class="math inline">\(x-y \in \ker T\)</span>, as desired. Next, we show <span class="math inline">\(\phi\)</span> is onto. Take any <span class="math inline">\(y \in \mathrm{im}(T)\)</span>. By definition there is some <span class="math inline">\(x \in V\)</span> mapping to <span class="math inline">\(y\)</span>. Then all of the vectors in <span class="math inline">\(x+\ker T\)</span> map to <span class="math inline">\(y\)</span>, as desired.</p>
<p>Hence the vector spaces are isomorphic.</p>
<p>Here’s a picture showing this:</p>
<figure>
<img src="data/firstisothm.png" alt="" /><figcaption>first isomorphism thm</figcaption>
</figure>
</div>
<p>Now rank nullity is evident. We simply need a small Lemma on the dimension of Quotient spaces:</p>
<div class="lem envbox">
<p><strong>Lemma.</strong> Let <span class="math inline">\(V\)</span> be a vector space, <span class="math inline">\(M \subset V\)</span> be a subspace. <span class="math display">\[\dim V/M = \dim V - \dim M.\]</span></p>
</div>
<div class="pf envbox">
<p><strong>Proof.</strong> Take a basis <span class="math inline">\(v_1,\ldots, v_m\)</span> for <span class="math inline">\(M\)</span>, extend it to a basis <span class="math inline">\(v_1,\ldots, v_n\)</span> for <span class="math inline">\(V\)</span>. Then <span class="math inline">\(M + v_{m+1}, \ldots, M+v_n\)</span> is a basis for <span class="math inline">\(V/M\)</span>. The basis has <span class="math display">\[n-m = \dim V - \dim M\]</span> elements. Hence <span class="math display">\[\dim V/M = \dim V - \dim M.\]</span></p>
</div>
Now we prove rank nullity
<div class="pf envbox">
<p><strong>Proof.</strong> By the first isomorphism theorem <span class="math display">\[V/\ker T = \mathrm{im} T.\]</span> By our lemma this implies <span class="math display">\[\dim V/\ker T = \dim V - \dim \ker T = \dim \mathrm{im} T\]</span> as desired.</p>
</div>
<h1 id="the-end">The End</h1>
<p>If you’re interested in Linear Algebra totally learn more about it! It’s pretty awesome IMHO.</p>
